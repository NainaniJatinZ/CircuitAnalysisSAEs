{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5365aa53-8458-494e-9e88-671bb82669e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import gc\n",
    "import torch\n",
    "os.chdir(\"/workspace/CircuitAnalysisSAEs\")\n",
    "from functools import partial\n",
    "from typing import Callable, Optional, Sequence, Tuple, Union, overload\n",
    "import einops\n",
    "import pandas as pd\n",
    "import torch\n",
    "from jaxtyping import Float, Int\n",
    "from tqdm.auto import tqdm\n",
    "from typing_extensions import Literal\n",
    "from transformer_lens.utils import Slice, SliceInput\n",
    "import sys \n",
    "import functools\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "import json\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from utils import plot\n",
    "from circ4latents import data_gen\n",
    "# sys.path.append(\"../../utils/\")\n",
    "with open(\"config.json\", 'r') as file:\n",
    "    config = json.load(file)\n",
    "    token = config.get('huggingface_token', None)\n",
    "os.environ[\"HF_TOKEN\"] = token\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "hf_cache = \"/workspace/hf_cache\"\n",
    "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556502f5-74d6-4444-b894-279d6c0623d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 23 07:37:34 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:81:00.0 Off |                    0 |\n",
      "| N/A   43C    P0             65W /  300W |   69611MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18638957-07a6-4df7-8ef0-aece30e4d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111d7ac925d04469a68004d992432ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-9b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedSAETransformer.from_pretrained(\"google/gemma-2-9b\", device=device, cache_dir=hf_cache)\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(release=\"gemma-scope-9b-pt-res-canonical\", sae_id=\"layer_10/width_16k/canonical\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61272a79-9740-4e8e-ba9d-389030f0201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847f429-16eb-40c0-93bd-d68f00fc452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "from tasks.error_detection.type.data import generate_samples\n",
    "\n",
    "selected_templates = [1] #, 2, 3, 4, 5]\n",
    "N = 50\n",
    "samples = generate_samples(selected_templates, N)\n",
    "for sample in samples[0]:\n",
    "    prompt = sample\n",
    "    print(prompt)\n",
    "\n",
    "# Token ID for \"Traceback\"\n",
    "traceback_token_id = model.tokenizer.encode(\"Traceback\", add_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fc35a-c3c4-415a-9550-9a7654a3ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pos  = {\n",
    "    \"s_start\": [],\n",
    "    \"s_end\": [],\n",
    "    \"i_start\": [],\n",
    "    \"i_end\": [],\n",
    "    \"end\": []\n",
    "}\n",
    "\n",
    "for i in range(N):\n",
    "    str_tokens_clean = model.to_str_tokens(samples[0][i])\n",
    "    str_tokens_corr = model.to_str_tokens(samples[1][i])\n",
    "    # Find the positions with differences\n",
    "    diff_positions = [i for i, (a, b) in enumerate(zip(str_tokens_clean, str_tokens_corr)) if a != b]\n",
    "\n",
    "    # Find positions of the first '(\"', the first '\"' after '(\"', and the end position\n",
    "    pos_open_paren_quote = str_tokens_clean.index('(\"')\n",
    "    pos_first_quote_after_open = pos_open_paren_quote + str_tokens_clean[pos_open_paren_quote:].index('\"') \n",
    "    pos_end = len(str_tokens_clean) - 1  # The last position\n",
    "\n",
    "    # Return the positions with differences, and the positions found\n",
    "    # print(diff_positions, pos_open_paren_quote, pos_first_quote_after_open, pos_end)\n",
    "    # print(str_tokens_clean[pos_first_quote_after_open])\n",
    "    selected_pos[\"s_start\"].append(pos_open_paren_quote)\n",
    "    selected_pos[\"s_end\"].append(pos_first_quote_after_open)\n",
    "    selected_pos[\"i_start\"].append(diff_positions[0])\n",
    "    selected_pos[\"i_end\"].append(diff_positions[-1])\n",
    "    selected_pos[\"end\"].append(pos_end)\n",
    "\n",
    "selected_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ae4e4d-9c94-45fd-bfa2-1d487258ab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4328, device='cuda:0')\n",
      "tensor(0.0895, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# %%\n",
    "\n",
    "def type_error_patch_metric_prob(logits, end_positions, err1_tok=traceback_token_id):\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    err1_logits = probs[range(logits.size(0)), end_positions, :][:, err1_tok]\n",
    "    return err1_logits.mean()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(samples[0])\n",
    "clean_diff = type_error_patch_metric_prob(logits, selected_pos['end'])\n",
    "print(clean_diff)\n",
    "with torch.no_grad():\n",
    "    logits = model(samples[1])\n",
    "corr_diff = type_error_patch_metric_prob(logits, selected_pos['end'])\n",
    "print(corr_diff)\n",
    "\n",
    "# %%\n",
    "\n",
    "def _err_type_metric(logits, clean_logit_diff, corr_logit_diff, end_positions):\n",
    "    patched_logit_diff = type_error_patch_metric_prob(logits, end_positions)\n",
    "    return (patched_logit_diff - corr_logit_diff) / (clean_logit_diff - corr_logit_diff)\n",
    "\n",
    "err_metric_denoising = partial(_err_type_metric, clean_logit_diff=clean_diff, corr_logit_diff=corr_diff, end_positions=selected_pos['end'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253093f1-0d58-4064-b182-e092078df0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "del logits\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71af007a-ed0e-4313-82e1-260baa519298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "# from torchtyping import TensorType as TT\n",
    "\n",
    "def get_cache_fwd_and_bwd(\n",
    "    model,\n",
    "    tokens,\n",
    "    metric,\n",
    "    sae,\n",
    "    error_term: bool = True,\n",
    "    retain_graph: bool = True\n",
    "):\n",
    "    # torch.set_grad_enabled(True)\n",
    "    model.reset_hooks()\n",
    "    # model.reset_saes()\n",
    "    cache = {}\n",
    "    grad_cache = {}\n",
    "    filter_base_acts = lambda name: \"blocks.10.hook_resid_post\" in name\n",
    "    # filter_sae_acts = lambda name: \"hook_sae_acts_post\" in name\n",
    "\n",
    "    def forward_cache_hook(act, hook):\n",
    "        act.requires_grad_(True)\n",
    "        # act.retain_graph()\n",
    "        cache[hook.name] = act.detach()\n",
    "\n",
    "    def backward_cache_hook(grad, hook):\n",
    "        grad.requires_grad_(True)\n",
    "        # grad.retain_graph()\n",
    "        grad_cache[hook.name] = grad.detach()\n",
    "\n",
    "    # sae.use_error_term = error_term\n",
    "    # model.add_sae(sae)\n",
    "    model.add_hook(filter_base_acts, forward_cache_hook, \"fwd\")\n",
    "    model.add_hook(filter_base_acts, backward_cache_hook, \"bwd\")\n",
    "    value = metric(model(tokens))\n",
    "    value.backward() #retain_graph=retain_graph)\n",
    "\n",
    "    model.reset_hooks()\n",
    "    # model.reset_saes()\n",
    "    # torch.set_grad_enabled(False)\n",
    "    return (\n",
    "        value,\n",
    "        ActivationCache(cache, model),\n",
    "        ActivationCache(grad_cache, model),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267aae9a-c530-423c-9994-a597d60c8f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Value: tensor(1., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Clean Activations Cached: 1\n",
      "Corrupted Value: tensor(0., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Corrupted Activations Cached: 1\n",
      "Corrupted Gradients Cached: 1\n"
     ]
    }
   ],
   "source": [
    "clean_value, clean_cache, _ = get_cache_fwd_and_bwd(model, samples[0], err_metric_denoising, sae)\n",
    "print(\"Clean Value:\", clean_value)\n",
    "print(\"Clean Activations Cached:\", len(clean_cache))\n",
    "# print(\"Clean Gradients Cached:\", len(clean_grad_cache))\n",
    "\n",
    "corrupted_value, corrupted_cache, corrupted_grad_cache = get_cache_fwd_and_bwd(model, samples[1], err_metric_denoising, sae)\n",
    "print(\"Corrupted Value:\", corrupted_value)\n",
    "print(\"Corrupted Activations Cached:\", len(corrupted_cache))\n",
    "print(\"Corrupted Gradients Cached:\", len(corrupted_grad_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e7f275-8915-4095-822a-e8d53bd90c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 33, 16384]) torch.Size([50, 33, 16384])\n"
     ]
    }
   ],
   "source": [
    "sae_acts = sae.encode(clean_cache['blocks.10.hook_resid_post'])\n",
    "sae_acts_corr = sae.encode(corrupted_cache['blocks.10.hook_resid_post'])\n",
    "print(sae_acts.shape, sae_acts_corr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928a6d2d-cb6a-4a95-bb02-e8d97a259287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 33, 16384])\n"
     ]
    }
   ],
   "source": [
    "sae_grad_cache = torch.einsum('bij,kj->bik', corrupted_grad_cache['blocks.10.hook_resid_post'], sae.W_dec)\n",
    "print(sae_grad_cache.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9944e0-f96f-437c-a036-ede74db69303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "import torch\n",
    "import einops\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Function to get HTML for a specific feature\n",
    "def get_dashboard_html(sae_release=\"gemma-2-9b\", sae_id=\"10-gemmascope-res-16k\", feature_idx=0):\n",
    "    html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "# Function to scrape the description for a feature\n",
    "def scrape_description(layer, feature_idx):\n",
    "    url = get_dashboard_html(sae_release=\"gemma-2-2b\", sae_id=f\"{layer}-gemmascope-res-16k\", feature_idx=feature_idx)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        soup_str = str(soup)\n",
    "\n",
    "        # Use regex to find the \"description\" field in the JSON structure\n",
    "        all_descriptions = re.findall(r'description\\\\\":\\\\\"(.*?)\",', soup_str)\n",
    "        \n",
    "        if all_descriptions:\n",
    "            return all_descriptions[-1]  # Return the last description\n",
    "        else:\n",
    "            return \"No description found.\"\n",
    "    else:\n",
    "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19baf1fe-7b51-4f59-8c48-3329785dac5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s_start': (tensor([7, 6, 4, 5, 1, 0, 2, 3, 8, 9], device='cuda:0'),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<IndexBackward0>)),\n",
       " 's_end': (tensor([7, 6, 4, 5, 1, 0, 2, 3, 8, 9], device='cuda:0'),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<IndexBackward0>)),\n",
       " 'i_start': (tensor([10694,  4718, 15358, 10207,   107,  5233,  6492,   430,  1911,   116],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0846,  0.0418,  0.0340,  0.0316, -0.0180,  0.0155,  0.0151, -0.0121,\n",
       "          -0.0118,  0.0108], device='cuda:0', grad_fn=<IndexBackward0>)),\n",
       " 'i_end': (tensor([ 2769,  9184, 14504, 12754,  7409,   771, 10182,  9154, 14819,  4482],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0794, -0.0248,  0.0098,  0.0093,  0.0083,  0.0081,  0.0079, -0.0075,\n",
       "           0.0074,  0.0072], device='cuda:0', grad_fn=<IndexBackward0>)),\n",
       " 'end': (tensor([ 6478,  8503, 13982,  2350,  1721,   632,  7500,  5730, 10406, 16010],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0044,  0.0040,  0.0027,  0.0027,  0.0026, -0.0026,  0.0020,  0.0018,\n",
       "          -0.0015,  0.0015], device='cuda:0', grad_fn=<IndexBackward0>))}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_per_pos = {}\n",
    "K = 10\n",
    "for idx, val in selected_pos.items():\n",
    "    # Get the selected activations and gradients\n",
    "    clean_residual_selected = sae_acts[torch.arange(sae_acts.shape[0]), val, :]\n",
    "    corr_residual_selected = sae_acts_corr[torch.arange(sae_acts_corr.shape[0]), val, :]\n",
    "    corr_grad_residual_selected = sae_grad_cache[torch.arange(sae_grad_cache.shape[0]), val, :]\n",
    "\n",
    "    # Residual attribution calculation only for the selected positions\n",
    "    residual_attr_final = einops.reduce(\n",
    "        corr_grad_residual_selected * (clean_residual_selected - corr_residual_selected),\n",
    "        \"batch n_features -> n_features\",\n",
    "        \"sum\",\n",
    "    )\n",
    "\n",
    "    # Get the top K features based on the absolute values\n",
    "    abs_residual_attr_final = torch.abs(residual_attr_final)\n",
    "    top_feats = torch.topk(abs_residual_attr_final, K)\n",
    "    \n",
    "    # Retrieve the top indices and the original signed values for these indices\n",
    "    top_indices = top_feats.indices\n",
    "    top_values = residual_attr_final[top_indices]  # Use original residual attribution values (with signs)\n",
    "\n",
    "    # Save the results\n",
    "    top_feats_per_pos[idx] = (top_indices, top_values)\n",
    "\n",
    "# %%\n",
    "top_feats_per_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4d8f464-2afa-421c-93c0-6e058d671280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "tensor([ 0.0846,  0.0418,  0.0340,  0.0316, -0.0180,  0.0155,  0.0151, -0.0121,\n",
      "        -0.0118,  0.0108], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([ 0.0794, -0.0248,  0.0098,  0.0093,  0.0083,  0.0081,  0.0079, -0.0075,\n",
      "         0.0074,  0.0072], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "tensor([ 0.0044,  0.0040,  0.0027,  0.0027,  0.0026, -0.0026,  0.0020,  0.0018,\n",
      "        -0.0015,  0.0015], device='cuda:0', grad_fn=<IndexBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl_latent_attr = 0\n",
    "for key, val in top_feats_per_pos.items():\n",
    "    print(val[1])\n",
    "    ttl_latent_attr += val[1].sum()\n",
    "\n",
    "ttl_latent_attr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa05445-834c-4dca-a8e6-216123766e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_final = einops.reduce(\n",
    "    corrupted_grad_cache['blocks.10.hook_resid_post'] * (clean_cache['blocks.10.hook_resid_post'] - corrupted_cache['blocks.10.hook_resid_post']),\n",
    "    \"batch pos d_model -> pos\",\n",
    "    \"sum\",\n",
    ")\n",
    "residual_attr_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a8d22e3-3170-478b-93b8-235a6ace77f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4154, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_final.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bc77b25-abdc-4253-b798-b94ffd2c1e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 33, 3584])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_clean_out = sae.decode(sae_acts)\n",
    "sae_clean_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d4532e4-8f94-4770-93d9-559a602c2361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s_start': (tensor([7, 6, 4, 5, 1, 0, 2, 3, 8, 9], device='cuda:0'),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<IndexBackward0>)),\n",
       " 's_end': (tensor([7, 6, 4, 5, 1, 0, 2, 3, 8, 9], device='cuda:0'),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "         grad_fn=<IndexBackward0>)),\n",
       " 'i_start': (tensor([10694,  4718, 15358, 10207,   107,  5233,  6492,   430,  1911,   116],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0846,  0.0418,  0.0340,  0.0316, -0.0180,  0.0155,  0.0151, -0.0121,\n",
       "          -0.0118,  0.0108], device='cuda:0', grad_fn=<IndexBackward0>)),\n",
       " 'i_end': (tensor([ 2769,  9184, 14504, 12754,  7409,   771, 10182,  9154, 14819,  4482],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0794, -0.0248,  0.0098,  0.0093,  0.0083,  0.0081,  0.0079, -0.0075,\n",
       "           0.0074,  0.0072], device='cuda:0', grad_fn=<IndexBackward0>)),\n",
       " 'end': (tensor([ 6478,  8503, 13982,  2350,  1721,   632,  7500,  5730, 10406, 16010],\n",
       "         device='cuda:0'),\n",
       "  tensor([ 0.0044,  0.0040,  0.0027,  0.0027,  0.0026, -0.0026,  0.0020,  0.0018,\n",
       "          -0.0015,  0.0015], device='cuda:0', grad_fn=<IndexBackward0>))}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_per_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68d05a7a-64d3-45c4-8fbd-2249385f1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: i_start\n",
      "Feature Index: 10694, Value: 0.08463253080844879\n",
      "structured textual formats or sections within documents\\\n",
      "Feature Index: 4718, Value: 0.04182133078575134\n",
      "instances of quotations or direct speech within the text\\\n",
      "Feature Index: 15358, Value: 0.03400522843003273\n",
      "references to statistical models or distributions\\\n",
      "Feature Index: 10207, Value: 0.03164256364107132\n",
      " elements and syntax related to programming and code structures\\\n",
      "Feature Index: 107, Value: -0.01801796443760395\n",
      "quoted strings and their formatting details\\\n",
      "Feature Index: 5233, Value: 0.015487908385694027\n",
      "different types of quotation marks and delimiters used in programming syntax\\\n",
      "Feature Index: 6492, Value: 0.015111686661839485\n",
      " coding syntax related to delimiters and string concatenation\\\n",
      "Feature Index: 430, Value: -0.012128639966249466\n",
      "documentation references and links related to APIs and guides\\\n",
      "Feature Index: 1911, Value: -0.011777937412261963\n",
      " symbols and operators related to coding syntax and structure\\\n",
      "Feature Index: 116, Value: 0.010787680745124817\n",
      " structural elements and formatting indicators within text\\\n",
      "Position: i_end\n",
      "Feature Index: 2769, Value: 0.07942334562540054\n",
      " punctuation and special characters used in code or programming syntax\\\n",
      "Feature Index: 9184, Value: -0.02482331171631813\n",
      "parenthetical expressions and mathematical notations\\\n",
      "Feature Index: 14504, Value: 0.009752769023180008\n",
      " expressions related to mathematical or programming operations\\\n",
      "Feature Index: 12754, Value: 0.009264115244150162\n",
      "programming structure and data manipulation concepts, particularly those related to strings and API requests\\\n",
      "Feature Index: 7409, Value: 0.008262782357633114\n",
      " structured programming elements and error handling in code\\\n",
      "Feature Index: 771, Value: 0.008136800490319729\n",
      "metadata and file information related to data representations and structures in various formats\\\n",
      "Feature Index: 10182, Value: 0.007937266491353512\n",
      " specific formatting or syntax elements related to coding or script structures\\\n",
      "Feature Index: 9154, Value: -0.007519484963268042\n",
      "various opening and closing bracket symbols and special characters\\\n",
      "Feature Index: 14819, Value: 0.0074095050804317\n",
      " concepts related to mathematical operations and programming functions\\\n",
      "Feature Index: 4482, Value: 0.007202492095530033\n",
      "mathematical expressions and equations\\\n",
      "Position: end\n",
      "Feature Index: 6478, Value: 0.004388418514281511\n",
      "indications of community involvement in various contexts\\\n",
      "Feature Index: 8503, Value: 0.003968451172113419\n",
      "events involving arrests and legal actions\\\n",
      "Feature Index: 13982, Value: 0.0027388613671064377\n",
      " programming syntax elements related to function definitions and exception handling\\\n",
      "Feature Index: 2350, Value: 0.002689684508368373\n",
      " elements and structures within programming or markup languages\\\n",
      "Feature Index: 1721, Value: 0.002603419590741396\n",
      " elements of code or structured data patterns\\\n",
      "Feature Index: 632, Value: -0.002553364960476756\n",
      " significant quantities or values in various contexts\\\n",
      "Feature Index: 7500, Value: 0.0019922868814319372\n",
      " numerical values, particularly those related to calculations and statistical analysis\\\n",
      "Feature Index: 5730, Value: 0.00179241260048002\n",
      " responses to questions, particularly answers that contain reasoning or personal insights\\\n",
      "Feature Index: 10406, Value: -0.001546568819321692\n",
      "phrases or words indicating comparisons or contrasts in arguments\\\n",
      "Feature Index: 16010, Value: 0.00154644506983459\n",
      "commands and functions related to shell scripting and file management tasks\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import einops\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Function to get HTML for a specific feature\n",
    "def get_dashboard_html(sae_release=\"gemma-2-9b\", sae_id=\"10-gemmascope-res-16k\", feature_idx=0):\n",
    "    html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "    return html_template.format(sae_release, sae_id, feature_idx)\n",
    "\n",
    "# Function to scrape the description for a feature\n",
    "def scrape_description(layer, feature_idx):\n",
    "    url = get_dashboard_html(sae_release=\"gemma-2-9b\", sae_id=f\"{layer}-gemmascope-res-16k\", feature_idx=feature_idx)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        soup_str = str(soup)\n",
    "\n",
    "        # Use regex to find the \"description\" field in the JSON structure\n",
    "        all_descriptions = re.findall(r'description\\\\\":\\\\\"(.*?)\",', soup_str)\n",
    "        \n",
    "        if all_descriptions:\n",
    "            return all_descriptions[-1]  # Return the last description\n",
    "        else:\n",
    "            return \"No description found.\"\n",
    "    else:\n",
    "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
    "\n",
    "# %%\n",
    "layer = 10\n",
    "top_10_features_for_rel_pos = {}\n",
    "interesting_keys = list(top_feats_per_pos.keys())[2:]\n",
    "# print(interesting_keys)\n",
    "for key in interesting_keys:\n",
    "    print(f\"Position: {key}\")\n",
    "    indices, values = top_feats_per_pos[key]\n",
    "    top_10_features_for_rel_pos[key] = []\n",
    "    for idx, val in zip(indices, values):\n",
    "        print(f\"Feature Index: {idx}, Value: {val}\")\n",
    "        description = scrape_description(layer, idx)\n",
    "        html_link = get_dashboard_html(sae_release=\"gemma-2-9b\", sae_id=\"10-gemmascope-res-16k\", feature_idx=idx)\n",
    "        print(description)\n",
    "        top_10_features_for_rel_pos[key].append((idx.item(), val.item(), description, html_link))\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('tasks/error_detection/type/out/layer10_top_10_features_for_rel_pos_abs.json', 'w') as json_file:\n",
    "    json.dump(top_10_features_for_rel_pos, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a271f8a0-6c82-42d4-86bb-236f897b266a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://neuronpedia.org/gemma-2-9b/10-gemmascope-res-16k/1000?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dashboard_html(sae_release=\"gemma-2-9b\", sae_id=\"10-gemmascope-res-16k\", feature_idx=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a73cd03e-30d8-4039-975c-21f0352b320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features for Position: i_start\n",
      "Heatmap saved: tasks/error_detection/type/out/layer10_features/heatmap_position_i_start_abs_stacked.png\n",
      "Top Features for Position: i_end\n",
      "Heatmap saved: tasks/error_detection/type/out/layer10_features/heatmap_position_i_end_abs_stacked.png\n",
      "Top Features for Position: end\n",
      "Heatmap saved: tasks/error_detection/type/out/layer10_features/heatmap_position_end_abs_stacked.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_and_save_position_heatmap(data_idx: int, position_name: str, top_features: list, str_tokens_clean: list, str_tokens_corr: list, clean_cache: dict, corr_cache: dict):\n",
    "    \"\"\"\n",
    "    Function to plot and save a heatmap for the top features in a given position.\n",
    "\n",
    "    Args:\n",
    "    - data_idx: Index of the specific prompt to visualize.\n",
    "    - position_name: The name of the position being analyzed (e.g., d1, d2, END).\n",
    "    - top_features: List of top features for the current position.\n",
    "    - str_tokens_clean: List of input tokens (strings) from the clean data.\n",
    "    - str_tokens_corr: List of input tokens (strings) from the corrupted data.\n",
    "    - clean_cache: Dictionary of activations from the clean cache.\n",
    "    - corr_cache: Dictionary of activations from the corrupted cache.\n",
    "\n",
    "    Returns:\n",
    "    - Saves the heatmap as a PNG file in the 'features' directory.\n",
    "    \"\"\"\n",
    "    activations_matrix = []\n",
    "\n",
    "    # Iterate over the top features (each feature has two rows: clean and corrupted)\n",
    "    for feature in top_features:\n",
    "        feature_idx = feature[0]\n",
    "\n",
    "        # Get activations from clean and corrupted caches\n",
    "        clean_activations = clean_cache[data_idx, :, feature_idx].cpu().detach().numpy()\n",
    "        corr_activations = corr_cache[data_idx, :, feature_idx].cpu().detach().numpy()\n",
    "\n",
    "        # Append clean and corrupted activations to the matrix\n",
    "        activations_matrix.append(clean_activations)\n",
    "        activations_matrix.append(corr_activations)\n",
    "\n",
    "    # Convert the activations matrix to a numpy array for plotting\n",
    "    activations_matrix = np.array(activations_matrix)\n",
    "\n",
    "    # Create a heatmap for the current position\n",
    "    plt.figure(figsize=(10, 6))  # Adjust the figure size based on the number of rows\n",
    "\n",
    "    plt.imshow(activations_matrix, aspect='auto', cmap='coolwarm')\n",
    "\n",
    "    # Create combined labels for x-axis by stacking clean and corrupted tokens\n",
    "    combined_tokens = [f\"{clean_token} | {corr_token}\" for clean_token, corr_token in zip(str_tokens_clean, str_tokens_corr)]\n",
    "\n",
    "    # Set x-axis to display the combined input tokens\n",
    "    plt.xticks(ticks=np.arange(len(combined_tokens)), labels=combined_tokens, rotation=90)\n",
    "\n",
    "    # Set y-axis labels to show clean and corrupted rows for each feature\n",
    "    y_ticks = []\n",
    "    for feature in top_features:\n",
    "        feature_idx = feature[0]\n",
    "        y_ticks.append(f'{feature_idx} (clean)')\n",
    "        y_ticks.append(f'{feature_idx} (corr)')\n",
    "\n",
    "    plt.yticks(ticks=np.arange(len(y_ticks)), labels=y_ticks)\n",
    "\n",
    "    # Add horizontal lines to separate clean and corrupted rows\n",
    "    for i in range(1, len(y_ticks), 2):  # Add line after every two rows\n",
    "        plt.axhline(i + 0.5, color='black', linewidth=1)\n",
    "        \n",
    "    # Add a color bar to the side\n",
    "    plt.colorbar(label='Activation Value')\n",
    "\n",
    "    # Set axis labels and title\n",
    "    plt.xlabel(\"Tokens (Clean / Corrupted)\")\n",
    "    plt.ylabel(\"Features (Clean and Corrupted)\")\n",
    "    plt.title(f\"Feature Activations for Position {position_name} (Top Features)\")\n",
    "    plt.subplots_adjust(left=0.25, right=0.9, top=0.9, bottom=0.3)  # Adjusted bottom for longer x-labels\n",
    "\n",
    "    # Create the 'features' directory if it doesn't exist\n",
    "    if not os.path.exists(\"features\"):\n",
    "        os.makedirs(\"features\")\n",
    "\n",
    "    # Save the heatmap as a PNG file\n",
    "    filename = f\"tasks/error_detection/type/out/layer10_features/heatmap_position_{position_name}_abs_stacked.png\"\n",
    "    plt.savefig(filename, bbox_inches=\"tight\")\n",
    "    plt.close()  # Close the plot to avoid display issues in loops\n",
    "\n",
    "    print(f\"Heatmap saved: {filename}\")\n",
    "\n",
    "# Example loop to generate heatmaps for each position\n",
    "for position_name, top_10_features in top_10_features_for_rel_pos.items():\n",
    "    print(f\"Top Features for Position: {position_name}\")\n",
    "\n",
    "    # Example input tokens (replace these with the actual input tokens for clean and corrupted)\n",
    "    str_tokens_clean = model.to_str_tokens(samples[0][0])  # Clean input tokens\n",
    "    str_tokens_corr = model.to_str_tokens(samples[1][0])  # Corrupted input tokens\n",
    "\n",
    "    # Generate and save the heatmap for the current position\n",
    "    plot_and_save_position_heatmap(data_idx=0, position_name=position_name, top_features=top_10_features, str_tokens_clean=str_tokens_clean, str_tokens_corr=str_tokens_corr, clean_cache=sae_acts, corr_cache=sae_acts_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c7ae4-6c4c-4c06-b74a-7da07a5550ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086eb6a5-27d5-4efa-a2ab-053aac65c8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9887f05-1d6b-4c23-8b99-d6530f31b4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea057f-2c5e-4517-8733-2cd83e1b7627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1a1c7-cc21-4d65-bc31-b151aa3466ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8b377-051f-4dad-b6bb-601c1a2c5834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6ede4e-094a-4d52-9cb1-c0160fac1dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd831a46-7510-47a3-88d1-386e25130953",
   "metadata": {},
   "source": [
    "# Error attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf4a3247-d881-411c-8ffe-eba182797094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 33, 3584]) torch.Size([50, 33, 3584])\n"
     ]
    }
   ],
   "source": [
    "error_clean_cache = sae.decode(sae_acts) - clean_cache['blocks.10.hook_resid_post']\n",
    "error_corr_cache = sae.decode(sae_acts_corr) - corrupted_cache['blocks.10.hook_resid_post'] \n",
    "print(error_clean_cache.shape, error_corr_cache.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bac4f-1b0a-4365-8778-ce2cf282e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_corr_grad = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241a545-56e3-47c5-8ae1-6a5b918a1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad ( in - out ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc157492-1e82-4759-bf3d-31461eb027a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad ( in - W_dec.W_enc. in ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bcec8-17bf-4e62-895c-f45cbac4d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad in -  grad (W_dec.W_enc. in ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdebb0c-24dc-4ebc-830b-dc2ba4998640",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad(in) -  W_dec.W_enc.grad(in) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f34cb0d0-1732-4df7-836f-99c4b5c188dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3584, 16384])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.W_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d59c2a2b-e2fa-40fd-845a-cc4667825078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 3584])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.W_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf078d-95d3-47bf-879c-aace38f7c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('ij,ji->1', sae.W_enc.shape, sae.W_dec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85d4ce74-8b85-4d38-8ab0-3be25d7470f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 33, 16384])\n"
     ]
    }
   ],
   "source": [
    "print(sae_grad_cache.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80a989e2-12aa-4670-95d1-081d5da18992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 33, 3584])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_err_try = torch.einsum('ijk,lk->ijl', sae_grad_cache, sae.W_enc)\n",
    "sae_err_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72d75914-d84d-41a5-a057-cf553126d069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 33, 3584])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_grad_cache['blocks.10.hook_resid_post'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd340b26-be36-48fe-8d66-124d46164d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7372, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_err_try = einops.reduce(\n",
    "    corrupted_grad_cache['blocks.10.hook_resid_post'] * error_clean_cache,\n",
    "    \"batch pos d_model -> pos\",\n",
    "    \"sum\",\n",
    ")\n",
    "residual_attr_err_try.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "598efe53-3274-47f1-a265-8f224dc72fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0626, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_err = einops.reduce(\n",
    "    corrupted_grad_cache['blocks.10.hook_resid_post'] * (error_clean_cache - error_corr_cache),\n",
    "    \"batch pos d_model -> pos\",\n",
    "    \"sum\",\n",
    ")\n",
    "residual_attr_err.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53a70b93-3f33-475a-a725-3e3689432798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4772, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_err = einops.reduce(\n",
    "    sae_err_try * (error_clean_cache - error_corr_cache),\n",
    "    \"batch pos d_model -> pos\",\n",
    "    \"sum\",\n",
    ")\n",
    "residual_attr_err.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b52bcb73-3557-4176-92c8-a34e081712ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4772, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_attr_err.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c22cbbe3-b192-4a6c-8afb-f50809f93b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, device='cuda:0')\n",
      "tensor(-8.3084e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sae.use_error_term = True\n",
    "    model.add_sae(sae)\n",
    "    logits = model(samples[0])\n",
    "    model.reset_saes()\n",
    "# clean_diff = type_error_patch_metric_prob(logits, selected_pos['end'])\n",
    "print(err_metric_denoising(logits))\n",
    "with torch.no_grad():\n",
    "    sae.use_error_term = True\n",
    "    model.add_sae(sae)\n",
    "    logits = model(samples[1])\n",
    "    model.reset_saes()\n",
    "corr_diff = type_error_patch_metric_prob(logits, selected_pos['end'])\n",
    "print(err_metric_denoising(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e5c806f-dd8d-4888-b5df-d029ecd357c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1318574256.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[44], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    without saes\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "without saes\n",
    "52 clean\n",
    "9 corr\n",
    "\n",
    "with saes \n",
    "24 clean\n",
    "15 corr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6819067c-360c-4411-af36-10d7b6ff1039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1930, device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_metric_denoising(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba504e4e-a404-49a6-b436-451e7b0dcf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8065e4-75ff-416f-ba23-50384231024c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13aa8475-e97b-4f34-9dfc-b277a6f26e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sae_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msae_out\u001b[49m \n\u001b[1;32m      6\u001b[0m sae_int \n",
      "\u001b[0;31mNameError\u001b[0m: name 'sae_out' is not defined"
     ]
    }
   ],
   "source": [
    "resi recons = sae_out - 3k \n",
    "\n",
    "w_dec - 16 x 3\n",
    "\n",
    "latents - 16k\n",
    "\n",
    "w_enc - 3 x 16 \n",
    "\n",
    "sae_in - 3k  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afe96f09-5fa5-437d-a0e2-a82a4c49038a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> print(\"my_var\" + 83)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14fb533f-043a-4f1a-8bb1-fc0be54d575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> print(\"my_var\" + \"83\")\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9de67ef-9d8d-4055-b536-c46e5387d94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 30,\n",
       " 32,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 32]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_pos['end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb47bb-8c40-446f-a224-56f628275212",
   "metadata": {},
   "source": [
    "# Feature patching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64a73fdb-ab72-444c-a686-6f94e61b748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 33, 16384])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9889c947-e888-4c57-a57d-40abb6cab127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 33, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [300, 1456, 7003]\n",
    "sae_acts[:, :, temp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e723d83-e0cb-479d-a171-453d6b0b50a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i_start': [[10694,\n",
       "   0.06348311901092529,\n",
       "   'words related to floral scents and their components\\\\'],\n",
       "  [4718,\n",
       "   0.04034152999520302,\n",
       "   'percentage indicators and formatting symbols\\\\'],\n",
       "  [15358,\n",
       "   0.03502115234732628,\n",
       "   'image references and their formatting in text\\\\'],\n",
       "  [10207, 0.030231375247240067, ' references to forums or discussions\\\\'],\n",
       "  [6492,\n",
       "   0.016979293897747993,\n",
       "   'terms related to nanotechnology and measurements\\\\'],\n",
       "  [16190,\n",
       "   0.010703159496188164,\n",
       "   ' programming constructs related to object-oriented features and function declarations\\\\'],\n",
       "  [5233,\n",
       "   0.010215678252279758,\n",
       "   'numerical data or statistics related to specific subjects\\\\'],\n",
       "  [13768,\n",
       "   0.009093033149838448,\n",
       "   'numerical values related to measurements or quantities\\\\'],\n",
       "  [116,\n",
       "   0.007796787656843662,\n",
       "   'keywords related to scientific concepts and phenomena involving particles and their interactions\\\\'],\n",
       "  [10669,\n",
       "   0.007719412446022034,\n",
       "   'structures or patterns typically used in mathematical expressions, particularly those involving matrices or arrays\\\\']],\n",
       " 'i_end': [[2769,\n",
       "   0.06516899168491364,\n",
       "   'names and references related to political figures and entities in German history\\\\'],\n",
       "  [12754,\n",
       "   0.009310038760304451,\n",
       "   'terms indicating comparison or exceptions in statements\\\\'],\n",
       "  [14819,\n",
       "   0.00850109476596117,\n",
       "   'instances of the word \\\\\\\\\\\\\"Meanwhile\\\\\\\\\\\\\" in various contexts\\\\'],\n",
       "  [771,\n",
       "   0.008174974471330643,\n",
       "   'metrics and measures related to variable performance and analysis in scientific data\\\\'],\n",
       "  [14504,\n",
       "   0.0069327643141150475,\n",
       "   'special characters or formatting symbols within the text\\\\'],\n",
       "  [4476,\n",
       "   0.006860965862870216,\n",
       "   'noises and sounds that are loud or disruptive\\\\'],\n",
       "  [4482,\n",
       "   0.006105905864387751,\n",
       "   ' phrases indicating explanations or justifications\\\\'],\n",
       "  [8668,\n",
       "   0.0051607172936201096,\n",
       "   'references to movies and their production details\\\\'],\n",
       "  [5172,\n",
       "   0.004903652239590883,\n",
       "   'method calls and property access within programming code\\\\'],\n",
       "  [7965,\n",
       "   0.004489578772336245,\n",
       "   'references to investigations, legal matters, and formal reports\\\\']],\n",
       " 'end': [[6478,\n",
       "   0.002789289690554142,\n",
       "   'terms and conditions related to contracts and agreements\\\\'],\n",
       "  [7500,\n",
       "   0.0016353520331904292,\n",
       "   'references to complex social or systemic themes, particularly those related to governance, metaphorical language around relationships, and the intersection of spirituality and societal structures\\\\'],\n",
       "  [13982,\n",
       "   0.0015904400497674942,\n",
       "   'conditional statements and error handling in programming code\\\\'],\n",
       "  [1721, 0.0014197928830981255, 'political views and affiliations\\\\'],\n",
       "  [8503,\n",
       "   0.0013248325558379292,\n",
       "   ' occurrences of the \\\\\\\\\\\\\"nil\\\\\\\\\\\\\" value in programming contexts, indicating missing or non-existent data\\\\'],\n",
       "  [5730,\n",
       "   0.0009995736181735992,\n",
       "   'terms that emphasize the utility and value of information\\\\'],\n",
       "  [8811,\n",
       "   0.0009294646442867815,\n",
       "   ' phrases related to judicial procedures and legal arguments about evidence and rulings\\\\'],\n",
       "  [2350,\n",
       "   0.0009289076551795006,\n",
       "   'references to male titles, particularly \\\\\\\\\\\\\"Mr.\\\\\\\\\\\\\" and \\\\\\\\\\\\\"Dr.\\\\\\\\\\\\\" in the text\\\\'],\n",
       "  [15306,\n",
       "   0.0008035062346607447,\n",
       "   'phrases indicating ease or simplicity in actions or processes\\\\'],\n",
       "  [10379,\n",
       "   0.0007687670877203345,\n",
       "   'references to bull sharks and their characteristics\\\\']]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open('tasks/error_detection/type/out/layer10_top_10_features_for_rel_pos.json', 'r') as json_file:\n",
    "    top_10_features_for_rel_pos = json.load(json_file)\n",
    "top_10_features_for_rel_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "345d146b-c61d-4b42-b5c2-11a69892b083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10694,\n",
       " 4718,\n",
       " 15358,\n",
       " 10207,\n",
       " 6492,\n",
       " 16190,\n",
       " 5233,\n",
       " 13768,\n",
       " 116,\n",
       " 10669,\n",
       " 2769,\n",
       " 12754,\n",
       " 14819,\n",
       " 771,\n",
       " 14504,\n",
       " 4476,\n",
       " 4482,\n",
       " 8668,\n",
       " 5172,\n",
       " 7965]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_feats = []\n",
    "for key, items in top_10_features_for_rel_pos.items(): \n",
    "    if key in ['i_start', 'i_end']:\n",
    "        for item in items:\n",
    "            imp_feats.append(item[0])\n",
    "imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe69d342-7682-414d-ac6d-45fac06ef3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_with_sae_features_list_with_hook(model, sae, clean_cache, corr_tokens, patching_metric, use_error_term=True, \n",
    "                                feature_list=None, next_token_column=True, progress_bar=True):\n",
    "    # Initialize batch and sequence size based on the activation store settings\n",
    "\n",
    "    def patching_hook(corrupted_activation, hook, clean_activation, feature_list):\n",
    "        corrupted_activation[:, :, feature_list, ...] = clean_activation[:, :, feature_list, ...]\n",
    "        return corrupted_activation\n",
    "    \n",
    "    # current_activation_name = utils.get_act_name(\"hook_sae_acts_post\", layer=0)\n",
    "    hook_point = sae.cfg.hook_name + '.hook_sae_acts_post'\n",
    "    # The hook function cannot receive additional inputs, so we use partial to include the specific index and the corresponding clean activation\n",
    "    current_hook = partial(\n",
    "        patching_hook,\n",
    "        clean_activation=clean_cache,\n",
    "        feature_list=feature_list\n",
    "    )\n",
    "\n",
    "    model.add_sae(sae)\n",
    "    sae.use_error_term = use_error_term\n",
    "    # Define the hook point in the model where the ablation hook will be attached\n",
    "    \n",
    "    model.add_hook(hook_point, current_hook, \"fwd\")\n",
    "    # Run the model with the hooks\n",
    "    with torch.no_grad():\n",
    "        patched_logits = model(corr_tokens)\n",
    "    value = patching_metric(patched_logits)\n",
    "    print(f\"patching metric output {value}\")\n",
    "\n",
    "    model.reset_hooks()\n",
    "    model.reset_saes()\n",
    "    sae.reset_hooks()\n",
    "    return patched_logits, value\n",
    "\n",
    "def non_patch(model, corr_tokens, patching_metric):\n",
    "    with torch.no_grad():\n",
    "        value = patching_metric(model(corr_tokens))\n",
    "    return value\n",
    "\n",
    "def non_patch_saes(model, sae, corr_tokens, patching_metric,  use_error_term=True):\n",
    "    model.add_sae(sae)\n",
    "    sae.use_error_term = use_error_term\n",
    "    with torch.no_grad():\n",
    "        value = patching_metric(model(corr_tokens))\n",
    "    model.reset_hooks()\n",
    "    model.reset_saes()\n",
    "    sae.reset_hooks()\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e63c3d-8fb3-426c-aee0-10516e162b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_patch(model, samples[1], err_metric_denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21436d2d-b54d-4412-bf05-20513731612b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2367, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_patch_saes(model, sae, samples[1], err_metric_denoising, use_error_term=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1538a98e-536c-4f11-8640-01fd3f1592c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4330, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_patch_saes(model, sae, samples[0], err_metric_denoising, use_error_term=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbab176a-18d1-49f2-bee1-d7ff7964f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching metric output -4.340986592410445e-08\n"
     ]
    }
   ],
   "source": [
    "p_logits, met_val = patch_with_sae_features_list_with_hook(model, sae, sae_acts, samples[1], err_metric_denoising, use_error_term=True, feature_list=imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "899565fd-6940-4584-93ca-3114e6b85200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2619, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abcd4423-d0df-463b-a52a-6177816c061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 23 07:40:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             64W /  300W |   69611MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad70f90-59d3-4aa8-b051-34916a81698e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 60.75 MiB is free. Process 1602148 has 79.07 GiB memory in use. Of the allocated memory 77.18 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnon_patch_saes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_metric_denoising\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_error_term\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 40\u001b[0m, in \u001b[0;36mnon_patch_saes\u001b[0;34m(model, sae, corr_tokens, patching_metric, use_error_term)\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39madd_sae(sae)\n\u001b[1;32m     39\u001b[0m sae\u001b[38;5;241m.\u001b[39muse_error_term \u001b[38;5;241m=\u001b[39m use_error_term\n\u001b[0;32m---> 40\u001b[0m value \u001b[38;5;241m=\u001b[39m patching_metric(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorr_tokens\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_hooks()\n\u001b[1;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_saes()\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:573\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    570\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 573\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:182\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    178\u001b[0m     mlp_in \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    179\u001b[0m         resid_mid \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_mlp_in(resid_mid\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     normalized_resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(mlp_in)\n\u001b[0;32m--> 182\u001b[0m     mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid_mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     resid_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_post(resid_mid \u001b[38;5;241m+\u001b[39m mlp_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:206\u001b[0m, in \u001b[0;36mTransformerBlock.apply_mlp\u001b[0;34m(self, normalized_resid)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_mlp\u001b[39m(\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m, normalized_resid: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Centralized point where the MLP is applied to the forward pass\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m        Float[torch.Tensor, \"batch pos d_model\"]: Our resulting tensor\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    208\u001b[0m         mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2_post(mlp_out)\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/saeenv/lib/python3.10/site-packages/transformer_lens/components/mlps/gated_mlp.py:70\u001b[0m, in \u001b[0;36mGatedMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     pre_linear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_pre_linear(\n\u001b[1;32m     66\u001b[0m         torch\u001b[38;5;241m.\u001b[39mmatmul(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_in)  \u001b[38;5;66;03m# batch pos d_model, d_model d_mlp -> batch pos d_mlp\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     post_act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_post(\n\u001b[0;32m---> 70\u001b[0m         (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_act\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_linear\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_in\n\u001b[1;32m     71\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_mlp]\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_addmm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_out, post_act)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 60.75 MiB is free. Process 1602148 has 79.07 GiB memory in use. Of the allocated memory 77.18 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "non_patch_saes(model, sae, samples[0], err_metric_denoising, use_error_term=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf00eb-37b1-4d2d-9551-4ea84844ecac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580fe648-5c77-46a3-bbda-6ab0693b86e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adaeea5b-6d71-4dbc-b514-30d3719ed372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> print(\"price\" + 7)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faf2d662-7581-48c8-8eb3-3659460c6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> print(\"price\" + \"7\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af1d2a-a39e-43c0-b136-806614fb94b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saeenv",
   "language": "python",
   "name": "saeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
