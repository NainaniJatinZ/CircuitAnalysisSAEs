{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5262aa52131d4e689d392823b1f9c85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-9b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/work/pi_jensen_umass_edu/jnainani_umass_edu/CircuitAnalysisSAEs/\")\n",
    "from functools import partial\n",
    "from typing import Callable, Optional, Sequence, Tuple, Union, overload\n",
    "import einops\n",
    "import pandas as pd\n",
    "import torch\n",
    "from jaxtyping import Float, Int\n",
    "from tqdm.auto import tqdm\n",
    "from typing_extensions import Literal\n",
    "from transformer_lens.utils import Slice, SliceInput\n",
    "import sys \n",
    "import functools\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "import json\n",
    "import os \n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "# import error_data\n",
    "sys.path.append(\"utils/\")\n",
    "import plot\n",
    "\n",
    "with open(\"config.json\", 'r') as file:\n",
    "    config = json.load(file)\n",
    "    token = config.get('huggingface_token', None)\n",
    "os.environ[\"HF_TOKEN\"] = token\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "hf_cache = \"/work/pi_jensen_umass_edu/jnainani_umass_edu/mechinterp/huggingface_cache/hub\"\n",
    "os.environ[\"HF_HOME\"] = \"/work/pi_jensen_umass_edu/jnainani_umass_edu/mechinterp/huggingface_cache/hub\"\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"google/gemma-2-9b\", device = device, cache_dir = hf_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'def', ' f', '(', 'nums', '):', '\\n', '    ', 'output', ' =', ' []', '\\n', '    ', 'for', ' n', ' in', ' nums', ':', '\\n', '        ', 'output', '.', 'append', '((', 'nums', '.', 'count', '(', 'n', '),', ' n', '))', '\\n', '    ', 'output', '.', 'sort', '(', 'reverse', '=', 'True', ')', '\\n', '    ', 'return', ' output', '\\n', '    ', '\\n', 'assert', ' f', '([', '1', ',', ' ', '1', ',', ' ', '3', ',', ' ', '1', ',', ' ', '3', ',', ' ', '1', '])', ' ==', ' [(']\n",
      "Tokenized answer: [' TypeError']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72056</span><span style=\"font-weight: bold\">    Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.02</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | TypeError|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m72056\u001b[0m\u001b[1m    Logit: \u001b[0m\u001b[1;36m-0.02\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | TypeError|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 29.79 Prob: 66.17% Token: |3|\n",
      "Top 1th token. Logit: 28.87 Prob: 26.38% Token: |4|\n",
      "Top 2th token. Logit: 26.79 Prob:  3.28% Token: |2|\n",
      "Top 3th token. Logit: 26.46 Prob:  2.37% Token: |5|\n",
      "Top 4th token. Logit: 25.73 Prob:  1.14% Token: |6|\n",
      "Top 5th token. Logit: 24.81 Prob:  0.46% Token: |1|\n",
      "Top 6th token. Logit: 23.13 Prob:  0.09% Token: |7|\n",
      "Top 7th token. Logit: 22.36 Prob:  0.04% Token: |0|\n",
      "Top 8th token. Logit: 21.93 Prob:  0.03% Token: |8|\n",
      "Top 9th token. Logit: 21.90 Prob:  0.02% Token: |9|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' TypeError'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72056</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' TypeError'\u001b[0m, \u001b[1;36m72056\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "prompt = \"\"\"def f(nums):\n",
    "    output = []\n",
    "    for n in nums:\n",
    "        output.append((nums.count(n), n))\n",
    "    output.sort(reverse=True)\n",
    "    return output\n",
    "    \n",
    "assert f([1, 1, 3, 1, 3, 1]) == [(\"\"\"\n",
    "test_prompt(prompt, \" TypeError\", model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff189a8e5694fb2b3bb190db3406e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(nums):\n",
      "    output = []\n",
      "    for n in nums:\n",
      "        output.append((nums.count(n), n))\n",
      "    output.sort(reverse=True)\n",
      "    return output\n",
      "    \n",
      "assert f([1, 1, 3, 1, 3, 1]) == [(3, 1), (2, 3)]\n",
      "assert f([1, 2,\n"
     ]
    }
   ],
   "source": [
    "print(model.generate(prompt, max_new_tokens=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important features in Benchmarks \n",
    "\n",
    "\n",
    "Idea: \n",
    "- pick a benchmark (newish) \n",
    "- For each forward pass, save the top k latents with 0 attribution patching \n",
    "- backward pass wrt - ce loss ? \n",
    "- manually or thorugh an LLM pick \"key\" tokens relevant to the answer\n",
    "- Average attribution over latents for these tokens over all data points \n",
    "- find cool and relevant latents that might potentially explain performance on the benchmark \n",
    "\n",
    "Why not? \n",
    "- too ambitious \n",
    "- very unprincipled \n",
    "- bag of tricks might cancel things out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eacc8c88904ec68877ef30d09309e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      "my_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
      "for key in [\"a\", \"b\", \"d\"]:\n",
      "    print(my_dict[key])\n",
      "error\n",
      "error is a built in type\n",
      "my_dict = {\"a\": 1, \"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> my_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    ">>> for key in [\"a\", \"b\", \"d\"]:\n",
    "...     print(my_dict[key])\n",
    "\"\"\"\n",
    "\n",
    "print(model.generate(prompt, max_new_tokens=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'Type', ' \"', 'help', '\",', ' \"', 'copyright', '\",', ' \"', 'credits', '\"', ' or', ' \"', 'license', '\"', ' for', ' more', ' information', '.', '\\n', 'fields', ' =', ' [\"', 'name', '\",', ' \"', 'age', '\",', ' \"', 'city', '\"]', '\\n', 'data', ' =', ' {\"', 'name', '\":', ' \"', 'Alice', '\",', ' \"', 'age', '\":', ' ', '2', '5', '}', '\\n', 'for', ' field', ' in', ' fields', ':', '\\n', '    ', 'print', '(', 'f', '\"{', 'field', '}:', ' {', 'data', '[', 'field', ']}', '\")', '\\n\\n', 'name', ':', ' Alice', '\\n', 'age', ':', ' ', '2', '5', '\\n']\n",
      "Tokenized answer: ['Traceback']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.64</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.55</span><span style=\"font-weight: bold\">% Token: |Traceback|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m24.64\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m12.55\u001b[0m\u001b[1m% Token: |Traceback|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 25.95 Prob: 46.44% Token: |<eos>|\n",
      "Top 1th token. Logit: 24.64 Prob: 12.55% Token: |Traceback|\n",
      "Top 2th token. Logit: 24.03 Prob:  6.78% Token: |city|\n",
      "Top 3th token. Logit: 23.93 Prob:  6.16% Token: |>>>|\n",
      "Top 4th token. Logit: 23.35 Prob:  3.44% Token: |```|\n",
      "Top 5th token. Logit: 23.15 Prob:  2.83% Token: |name|\n",
      "Top 6th token. Logit: 22.99 Prob:  2.40% Token: |</code>|\n",
      "Top 7th token. Logit: 22.64 Prob:  1.70% Token: |----------------|\n",
      "Top 8th token. Logit: 22.04 Prob:  0.93% Token: |'''|\n",
      "Top 9th token. Logit: 21.92 Prob:  0.82% Token: |Syntax|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Traceback'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Traceback'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> fields = [\"name\", \"age\", \"city\"]\n",
    ">>> data = {\"name\": \"Alice\", \"age\": 25}\n",
    ">>> for field in fields:\n",
    "...     print(f\"{field}: {data[field]}\")\n",
    "... \n",
    "name: Alice\n",
    "age: 25\n",
    "\"\"\"\n",
    "test_prompt(prompt, \"Traceback\", model, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for idx, elem in enumerate(numbers):\n",
      "        for idx2, elem2 in enumerate(numbers):\n",
      "            if idx != idx2:\n",
      "                distance = abs(elem - elem2)\n",
      "                if distance < threshold:\n",
      "                    return True\n",
      "\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', 'You', ' are', ' given', ' a', ' Python', ' function', ' and', ' a', ' question', ' on', ' the', ' function', '.', ' Answer', ' the', ' question', ' with', ' only', ' YES', ' or', ' NO', ',', ' considering', ' executing', ' the', ' provided', ' code', ' on', ' the', ' given', ' input', ',', ' even', ' if', ' the', ' function', ' is', ' incorrect', ' or', ' incomplete', '.', ' Do', ' NOT', ' output', ' any', ' extra', ' information', '.', '\\n\\n', '```', 'python', '\\n', 'from', ' typing', ' import', ' List', '\\n\\n', 'def', ' has', '_', 'close', '_', 'elements', '(', 'numbers', ':', ' List', '[', 'float', '],', ' threshold', ':', ' float', ')', ' ->', ' bool', ':', '\\n', '    ', '#', ' Check', ' if', ' in', ' given', ' list', ' of', ' numbers', ',', ' are', ' any', ' two', ' numbers', ' closer', ' to', ' each', ' other', ' than', ' given', ' threshold', '.', '\\n', '    ', 'for', ' idx', ',', ' elem', ' in', ' enumerate', '(', 'numbers', '):', '\\n', '        ', 'for', ' idx', '2', ',', ' elem', '2', ' in', ' enumerate', '(', 'numbers', '):', '\\n', '            ', 'if', ' idx', ' !=', ' idx', '2', ':', '\\n', '                ', 'distance', ' =', ' abs', '(', 'elem', ' -', ' elem', '2', ')', ' #', ' Line', ' A', '\\n', '                ', 'if', ' distance', ' <', ' threshold', ':', ' ', '\\n', '                    ', 'return', ' True', ' #', ' Line', ' B', '\\n\\n', '    ', 'return', ' False', '\\n', 'has', '_', 'close', '_', 'elements', '([', '1', '.', '0', ',', ' ', '2', '.', '0', ',', ' ', '3', '.', '0', '],', ' ', '0', '.', '5', ')', '\\n', '```', '\\n', 'Question', ':', ' Will', ' Line', ' B', ' be', ' executed', '?', '\\n', 'Answer', ':']\n",
      "Tokenized answer: ['YES']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.68</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.20</span><span style=\"font-weight: bold\">% Token: |YES|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m26\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m21.68\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1m% Token: |YES|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 26.84 Prob: 35.32% Token: | YES|\n",
      "Top 1th token. Logit: 26.21 Prob: 18.89% Token: | NO|\n",
      "Top 2th token. Logit: 25.57 Prob:  9.92% Token: |\n",
      "|\n",
      "Top 3th token. Logit: 24.96 Prob:  5.41% Token: |<eos>|\n",
      "Top 4th token. Logit: 24.50 Prob:  3.42% Token: | |\n",
      "Top 5th token. Logit: 24.45 Prob:  3.24% Token: |\n",
      "\n",
      "|\n",
      "Top 6th token. Logit: 24.43 Prob:  3.19% Token: | Yes|\n",
      "Top 7th token. Logit: 24.29 Prob:  2.75% Token: | [|\n",
      "Top 8th token. Logit: 23.95 Prob:  1.96% Token: | No|\n",
      "Top 9th token. Logit: 23.73 Prob:  1.58% Token: | `|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'YES'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'YES'\u001b[0m, \u001b[1;36m26\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are given a Python function and a question on the function. Answer the question with only YES or NO, considering executing the provided code on the given input, even if the function is incorrect or incomplete. Do NOT output any extra information.\n",
    "\n",
    "```python\n",
    "from typing import List\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    # Check if in given list of numbers, are any two numbers closer to each other than given threshold.\n",
    "    for idx, elem in enumerate(numbers):\n",
    "        for idx2, elem2 in enumerate(numbers):\n",
    "            if idx != idx2:\n",
    "                distance = abs(elem - elem2) # Line A\n",
    "                if distance < threshold: \n",
    "                    return True # Line B\n",
    "\n",
    "    return False\n",
    "has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
    "```\n",
    "Question: Will Line B be executed?\n",
    "Answer:\"\"\"\n",
    "test_prompt(prompt, \"YES\", model, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Coverage Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', '\\n', 'You', ' are', ' given', ' a', ' Python', ' function', ' and', ' a', ' question', ' on', ' the', ' function', '.', ' Answer', ' the', ' question', ' with', ' only', ' YES', ' or', ' NO', ',', ' considering', ' executing', ' the', ' provided', ' code', ' on', ' the', ' given', ' input', ',', ' even', ' if', ' the', ' function', ' is', ' incorrect', ' or', ' incomplete', '.', ' Do', ' NOT', ' output', ' any', ' extra', ' information', '.', '\\n', '```', 'python', '\\n', 'x', ' =', ' ', '2', '\\n', 'if', ' x', ' >', ' ', '5', ':', '\\n', '    ', 'print', '(\"', 'Greater', ' than', ' ', '5', '\")', '  ', '#', ' Line', ' A', '\\n', 'else', ':', '\\n', '    ', 'print', '(\"', 'Not', ' greater', ' than', ' ', '5', '\")', '  ', '#', ' Line', ' B', '\\n', '```', '\\n', 'Question', ':', ' Will', ' Line', ' B', ' be', ' executed', '?', '\\n', 'Answer', ':']\n",
      "Tokenized answer: ['YES']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.11</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17</span><span style=\"font-weight: bold\">% Token: |YES|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m22\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m21.11\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.17\u001b[0m\u001b[1m% Token: |YES|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 26.47 Prob: 34.85% Token: | YES|\n",
      "Top 1th token. Logit: 26.36 Prob: 31.41% Token: | NO|\n",
      "Top 2th token. Logit: 25.15 Prob:  9.38% Token: |\n",
      "|\n",
      "Top 3th token. Logit: 23.97 Prob:  2.88% Token: | No|\n",
      "Top 4th token. Logit: 23.82 Prob:  2.48% Token: | Yes|\n",
      "Top 5th token. Logit: 23.76 Prob:  2.33% Token: | `|\n",
      "Top 6th token. Logit: 23.63 Prob:  2.04% Token: | |\n",
      "Top 7th token. Logit: 23.50 Prob:  1.79% Token: | ```|\n",
      "Top 8th token. Logit: 23.42 Prob:  1.66% Token: |\n",
      "\n",
      "|\n",
      "Top 9th token. Logit: 23.42 Prob:  1.65% Token: | [|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'YES'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'YES'\u001b[0m, \u001b[1;36m22\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are given a Python function and a question on the function. Answer the question with only YES or NO, considering executing the provided code on the given input, even if the function is incorrect or incomplete. Do NOT output any extra information.\n",
    "```python\n",
    "x = 2\n",
    "if x > 5:\n",
    "    print(\"Greater than 5\")  # Line A\n",
    "else:\n",
    "    print(\"Not greater than 5\")  # Line B\n",
    "```\n",
    "Question: Will Line B be executed?\n",
    "Answer:\"\"\"\n",
    "test_prompt(prompt, \"YES\", model, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<bos>', '```', 'python', '\\n', 'def', ' check', '(', 'x', '):', '\\n', '    ', 'if', ' x', ' >', ' ', '0', ':', '\\n', '        ', 'print', '(\"', 'Positive', '\")', '  ', '#', ' Line', ' A', '\\n\\n', 'check', '(-', '1', ')', '\\n', '```', '\\n', 'Question', ':', ' Will', ' Line', ' A', ' be', ' executed', '?', '\\n', 'Answer', ':']\n",
      "Tokenized answer: ['YES']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">352</span><span style=\"font-weight: bold\">      Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.59</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: |YES|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m352\u001b[0m\u001b[1m      Logit: \u001b[0m\u001b[1;36m16.59\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: |YES|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 27.53 Prob: 46.12% Token: | No|\n",
      "Top 1th token. Logit: 26.08 Prob: 10.84% Token: | Yes|\n",
      "Top 2th token. Logit: 25.80 Prob:  8.18% Token: | False|\n",
      "Top 3th token. Logit: 24.77 Prob:  2.91% Token: |\n",
      "|\n",
      "Top 4th token. Logit: 24.76 Prob:  2.90% Token: | Line|\n",
      "Top 5th token. Logit: 24.58 Prob:  2.43% Token: | True|\n",
      "Top 6th token. Logit: 24.29 Prob:  1.81% Token: | |\n",
      "Top 7th token. Logit: 24.29 Prob:  1.80% Token: |  |\n",
      "Top 8th token. Logit: 24.25 Prob:  1.73% Token: | A|\n",
      "Top 9th token. Logit: 24.24 Prob:  1.71% Token: | NO|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'YES'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">352</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'YES'\u001b[0m, \u001b[1;36m352\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"```python\n",
    "def check(x):\n",
    "    if x > 0:\n",
    "        print(\"Positive\")  # Line A\n",
    "\n",
    "check(-1)\n",
    "```\n",
    "Question: Will Line A be executed?\n",
    "Answer:\"\"\"\n",
    "test_prompt(prompt, \"YES\", model, prepend_space_to_answer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
