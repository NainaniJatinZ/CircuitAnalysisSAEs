{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM, SAEs\n",
    "\n",
    "sae layers: [7, 14, 21, 28, 40]\n",
    "llm gemma 9b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T07:43:04.890895Z",
     "start_time": "2024-11-27T07:42:34.748286Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea38b110a7845ada913c9554bade36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-9b into HookedTransformer\n",
      "pad token id is 0\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import circuitsvis as cv\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.set_default_device(device)\n",
    "# assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "\n",
    "import transformer_lens\n",
    "\n",
    "# Load a model\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gemma-2-9b\", device=\"cuda\")\n",
    "pad_token_id = model.tokenizer.pad_token_id\n",
    "print('pad token id is', pad_token_id)\n",
    "\n",
    "for param in model.parameters():\n",
    "   param.requires_grad_(False)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE, HookedSAETransformer\n",
    "layers= [7, 14, 21, 40]\n",
    "l0s = [92, 67, 129, 125]\n",
    "saes = [SAE.from_pretrained(release=\"gemma-scope-9b-pt-res\", sae_id=f\"layer_{layers[i]}/width_16k/average_l0_{l0s[i]}\", device=device)[0] for i in range(len(layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import signal\n",
    "# import torch.nn as nn\n",
    "# class KeyboardInterruptBlocker:\n",
    "#     def __enter__(self):\n",
    "#         # Ignore SIGINT (KeyboardInterrupt) and save the old handler\n",
    "#         self.original_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "#     def __exit__(self, exc_type, exc_value, traceback):\n",
    "#         # Restore the original SIGINT handler\n",
    "#         signal.signal(signal.SIGINT, self.original_handler)\n",
    "# class SparseMask(nn.Module):\n",
    "#     def __init__(self, shape, l1, seq_len=None):\n",
    "#         super().__init__()\n",
    "#         if seq_len is not None:\n",
    "#             self.mask = nn.Parameter(torch.ones(seq_len, shape))\n",
    "#         else:\n",
    "#             self.mask = nn.Parameter(torch.ones(shape))\n",
    "#         self.l1 = l1\n",
    "#         self.max_temp = torch.tensor(1000.0)\n",
    "#         self.sparsity_loss = None\n",
    "#         self.ratio_trained = 1\n",
    "#         self.temperature = 1\n",
    "#     def forward(self, x, binary=False, mean_ablation=None):\n",
    "#         if binary and mean_ablation is not None:\n",
    "#             binarized = (self.mask > 0).float().to(x.device)\n",
    "#             return x * binarized + mean_ablation * (~binarized.bool())\n",
    "#         if binary:\n",
    "#             # binary mask, 0 if negative, 1 if positive\n",
    "#             binarized = (self.mask > 0).float()\n",
    "#             return x * binarized\n",
    "#         self.temperature = self.max_temp ** self.ratio_trained\n",
    "#         mask = torch.sigmoid(self.mask * self.temperature)\n",
    "#         self.sparsity_loss = torch.abs(mask).sum() * self.l1\n",
    "#         if mean_ablation is None:\n",
    "#             return x * mask\n",
    "#         else:\n",
    "#             return x * mask + mean_ablation * (~mask.bool())\n",
    "# # for sae in saes:\n",
    "# #     sae.mask = SparseMask(sae.cfg.d_sae, 1.0, seq_len=67)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated version to return JSON with more names and structure for correct and incorrect keying examples\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Expanding the name pool with a larger set of names\n",
    "extended_name_pool = [\n",
    "    \"Bob\", \"Sam\", \"Lilly\", \"Rob\", \"Alice\", \"Charlie\", \"Sally\", \"Tom\", \"Jake\", \"Emily\", \n",
    "    \"Megan\", \"Chris\", \"Sophia\", \"James\", \"Oliver\", \"Isabella\", \"Mia\", \"Jackson\", \n",
    "    \"Emma\", \"Ava\", \"Lucas\", \"Benjamin\", \"Ethan\", \"Grace\", \"Olivia\", \"Liam\", \"Noah\"\n",
    "]\n",
    "\n",
    "for name in extended_name_pool:\n",
    "    assert len(model.tokenizer.encode(name)) == 2, f\"Name {name} has more than 1 token\"\n",
    "\n",
    "# Function to generate the dataset with correct and incorrect keying into dictionaries\n",
    "def generate_extended_dataset(name_pool, num_samples=5):\n",
    "    dataset = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Randomly select 5 names from the pool\n",
    "        selected_names = random.sample(name_pool, 5)\n",
    "        # Assign random ages to the selected names\n",
    "        age_dict = {name: random.randint(10, 19) for name in selected_names}\n",
    "        \n",
    "        # Create a correct example\n",
    "        correct_name = random.choice(list(age_dict.keys()))\n",
    "        correct_prompt = f'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> age = {age_dict}\\n>>> age[\"{correct_name}\"]\\n'\n",
    "        correct_response = age_dict[correct_name]\n",
    "        correct_token = str(correct_response)[0]\n",
    "        \n",
    "        # Create an incorrect example with a name not in the dictionary\n",
    "        incorrect_name = random.choice([name for name in name_pool if name not in age_dict])\n",
    "        incorrect_prompt = f'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> age = {age_dict}\\n>>> age[\"{incorrect_name}\"]\\n'\n",
    "        incorrect_response = \"Traceback\"\n",
    "        incorrect_token = \"Traceback\"\n",
    "        \n",
    "        # Append the pair of correct and incorrect examples\n",
    "        dataset.append({\n",
    "            \"correct\": {\n",
    "                \"prompt\": correct_prompt,\n",
    "                \"response\": correct_response,\n",
    "                \"token\": correct_token\n",
    "            },\n",
    "            \"error\": {\n",
    "                \"prompt\": incorrect_prompt,\n",
    "                \"response\": incorrect_response,\n",
    "                \"token\": incorrect_token\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Generate the extended dataset\n",
    "json_dataset = generate_extended_dataset(extended_name_pool, num_samples=100_000)\n",
    "\n",
    "# Output the JSON structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dataset_ex_len = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': {'prompt': 'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> age = {\\'Megan\\': 10, \\'Grace\\': 16, \\'Liam\\': 18, \\'Sally\\': 10, \\'Emily\\': 11}\\n>>> age[\"Liam\"]\\n',\n",
       "  'response': 18,\n",
       "  'token': '1'},\n",
       " 'error': {'prompt': 'Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> age = {\\'Megan\\': 10, \\'Grace\\': 16, \\'Liam\\': 18, \\'Sally\\': 10, \\'Emily\\': 11}\\n>>> age[\"Sophia\"]\\n',\n",
       "  'response': 'Traceback',\n",
       "  'token': 'Traceback'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2, 235285,   1154,   4506,      0,      0],\n",
       "        [     2, 235285,   1154,  11514,    578,   4506],\n",
       "        [     2,  39954,      0,      0,      0,      0],\n",
       "        [     2,  34371,      0,      0,      0,      0]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = model.to_tokens([\"I like pie\", \"I like cake and pie\", \"birds\", 'cats'])\n",
    "torch.count_nonzero(tokenized != pad_token_id, dim=-1)-1\n",
    "tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2, 3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensa = torch.tensor([1,2,3,])\n",
    "tesb = torch.tensor([1,2,3,4])\n",
    "torch.cat([tensa, tesb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDatasetBatch:\n",
    "    def __init__(self, dataset_items):\n",
    "        self.correct_batch = [item[\"correct\"] for item in dataset_items]\n",
    "        self.error_batch = [item[\"error\"] for item in dataset_items]\n",
    "        self.batch_size = len(self.correct_batch)\n",
    "        self.correct_token_idx = model.to_single_token(\"1\")\n",
    "        self.error_token_idx = model.to_single_token(\"Traceback\")\n",
    "\n",
    "        correct_tokenized = None\n",
    "        error_tokenized = None\n",
    "\n",
    "        correct_prompts = [example[\"prompt\"] for example in self.correct_batch]\n",
    "        error_prompts = [example[\"prompt\"] for example in self.error_batch]\n",
    "        assert len(correct_prompts) == len(error_prompts)\n",
    "        all_prompts = correct_prompts + error_prompts\n",
    "        all_tokenized = model.to_tokens(all_prompts)\n",
    "        last_non_pad_idxs = torch.count_nonzero(all_tokenized != pad_token_id, dim=-1) - 1\n",
    "\n",
    "\n",
    "        correct_tokenized = all_tokenized[:self.batch_size]\n",
    "        correct_answer_idxs = last_non_pad_idxs[:self.batch_size]\n",
    "        error_tokenized = all_tokenized[self.batch_size:]\n",
    "        error_answer_idxs = last_non_pad_idxs[self.batch_size:]\n",
    "\n",
    "        self.correct_tokenized = correct_tokenized\n",
    "        self.error_tokenized = error_tokenized\n",
    "        self.correct_answer_seq_idxs = correct_answer_idxs\n",
    "        self.error_answer_seq_idxs = error_answer_idxs\n",
    "\n",
    "        self.all_tokenized = all_tokenized\n",
    "        self.all_answer_seq_idxs = last_non_pad_idxs\n",
    "        self.all_prompts = all_prompts\n",
    "        # the tokens are: [correct prompt, correct prompt, ..., error prompt, error prompt, ...]\n",
    "        self.all_answers_tok_idxs = torch.cat(\n",
    "            [\n",
    "                torch.ones(self.batch_size, dtype=torch.int64)*self.correct_token_idx,\n",
    "                torch.ones(self.batch_size, dtype=torch.int64)*self.error_token_idx\n",
    "            ]\n",
    "            )\n",
    "        self.all_wrong_answers_tok_idxs = torch.cat(\n",
    "            [\n",
    "                torch.ones(self.batch_size, dtype=torch.int64)*self.error_token_idx,\n",
    "                torch.ones(self.batch_size, dtype=torch.int64)*self.correct_token_idx\n",
    "            ]\n",
    "            )\n",
    "    \n",
    "    def get_logit_diffs(self, clean_logits, error_logits):\n",
    "        # for the clean pass, get the logit for the \"1\" token and the \"Traceback\" token\n",
    "        correct_code_right_logits = clean_logits[torch.arange(self.batch_size), self.correct_answer_seq_idxs, self.correct_token_idx]\n",
    "        correct_code_wrong_logits = clean_logits[torch.arange(self.batch_size), self.correct_answer_seq_idxs, self.error_token_idx]\n",
    "        correct_logit_diffs = correct_code_right_logits - correct_code_wrong_logits\n",
    "\n",
    "        # for the error pass, get the logit for the Traceback token and the \"1\" token\n",
    "        error_code_right_logits = error_logits[torch.arange(self.batch_size), self.error_answer_seq_idxs, self.error_token_idx]\n",
    "        error_code_wrong_logits = error_logits[torch.arange(self.batch_size), self.error_answer_seq_idxs, self.correct_token_idx]\n",
    "        error_logit_diffs = error_code_right_logits - error_code_wrong_logits\n",
    "        return {\"correct_code_diff\": correct_logit_diffs, \"error_code_diff\": error_logit_diffs}\n",
    "        \n",
    "\n",
    "\n",
    "eval_dataset = ContrastiveDatasetBatch(json_dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dataset = []\n",
    "simple_labels = []\n",
    "\n",
    "answer_token = model.to_single_token(\"1\")\n",
    "traceback_token = model.to_single_token(\"Traceback\")\n",
    "\n",
    "for item in json_dataset:\n",
    "    simple_dataset.append(item[\"correct\"][\"prompt\"])\n",
    "    simple_dataset.append(item[\"error\"][\"prompt\"])\n",
    "    simple_labels.append(answer_token)\n",
    "    simple_labels.append(traceback_token)\n",
    "\n",
    "\n",
    "simple_dataset = model.to_tokens(simple_dataset)\n",
    "simple_labels = torch.tensor(simple_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = torch.randperm(len(simple_dataset))\n",
    "simple_dataset = simple_dataset[permutation]\n",
    "simple_labels = simple_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:'\n",
      "'\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Traceback'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"token:'{model.to_str_tokens(eval_dataset.all_tokenized[15])[eval_dataset.all_answer_seq_idxs[15]]}'\")\n",
    "print(\"Answer:\")\n",
    "model.to_string([eval_dataset.all_answers_tok_idxs[15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class KeyboardInterruptBlocker:\n",
    "    def __enter__(self):\n",
    "        # Ignore SIGINT (KeyboardInterrupt) and save the old handler\n",
    "        self.original_handler = signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        # Restore the original SIGINT handler\n",
    "        signal.signal(signal.SIGINT, self.original_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class SparseMask(nn.Module):\n",
    "    def __init__(self, shape, l1, seq_len=None):\n",
    "        super().__init__()\n",
    "        if seq_len is not None:\n",
    "            self.mask = nn.Parameter(torch.ones(seq_len, shape))\n",
    "        else:\n",
    "            self.mask = nn.Parameter(torch.ones(shape))\n",
    "        self.l1 = l1\n",
    "        self.max_temp = torch.tensor(1000.0)\n",
    "        self.sparsity_loss = None\n",
    "        self.ratio_trained = 1\n",
    "        self.temperature = 1\n",
    "\n",
    "\n",
    "    def forward(self, x, binary=False, mean_ablation=None):\n",
    "        if binary:\n",
    "            # binary mask, 0 if negative, 1 if positive\n",
    "            binarized = (self.mask > 0).float()\n",
    "            if mean_ablation is None:\n",
    "                return x * binarized\n",
    "            else:\n",
    "                diff = x - mean_ablation\n",
    "                return diff * binarized + mean_ablation\n",
    "            \n",
    "\n",
    "        self.temperature = self.max_temp ** self.ratio_trained\n",
    "        mask = torch.sigmoid(self.mask * self.temperature)\n",
    "        self.sparsity_loss = torch.abs(mask).sum() * self.l1\n",
    "\n",
    "        if mean_ablation is None:\n",
    "            return x * mask\n",
    "        else:\n",
    "            diff = x - mean_ablation\n",
    "            return diff * mask + mean_ablation\n",
    "\n",
    "\n",
    "\n",
    "for sae in saes:\n",
    "    sae.mask = SparseMask(sae.cfg.d_sae, 1.0, seq_len=65)\n",
    "# saes[0].mask = SparseMask(saes[0].cfg.d_sae, 1.0)\n",
    "# saes[1].mask = SparseMask(saes[1].cfg.d_sae, 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 16384])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saes[3].mask.mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(mask_idxs, sae):\n",
    "    mask = torch.full_like(sae.mask.mask, -10)\n",
    "    mask[mask_idxs] = 10\n",
    "    sae.mask.mask.data = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparsemask(mask_path):\n",
    "    json_mask = json.load(open(mask_path))\n",
    "    for sae in saes:\n",
    "        apply_mask(json_mask[sae.cfg.hook_name], sae)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token_id = model.tokenizer.bos_token_id\n",
    "\n",
    "def build_sae_hook_fn(sae, sequence, cache_grads=False, circuit_mask=None, use_mask=False, binarize_mask=False, cache_masked_activations=False, cache_sae_activations=False,  mean_mask=False, mean_ablate=False): # mean_ablate mean ablates the SAE\n",
    "    # make the mask for the sequence\n",
    "    mask = torch.ones_like(sequence, dtype=torch.bool)\n",
    "    mask[sequence == pad_token_id] = False\n",
    "    mask[sequence == bos_token_id] = False # where mask is false, keep original\n",
    "    def sae_hook(value, hook):\n",
    "        # print(f\"sae {sae.cfg.hook_name} running at layer {hook.layer()}\")\n",
    "        feature_acts = sae.encode(value)\n",
    "        if cache_grads:\n",
    "            sae.feature_acts = feature_acts\n",
    "            sae.feature_acts.retain_grad()\n",
    "        \n",
    "        if cache_sae_activations:\n",
    "            sae.feature_acts = feature_acts.detach().clone()\n",
    "        \n",
    "        # apply the mask, with configurable options\n",
    "        if use_mask:\n",
    "            if mean_mask:\n",
    "                # apply the mask, with mean ablations\n",
    "                feature_acts = sae.mask(feature_acts, binary=binarize_mask, mean_ablation=sae.mean_ablation)\n",
    "            else:\n",
    "                # apply the mask, without mean ablations\n",
    "                feature_acts = sae.mask(feature_acts, binary=binarize_mask)\n",
    "\n",
    "        if circuit_mask is not None:\n",
    "            mask_method = circuit_mask['mask_method']\n",
    "            mask_indices = circuit_mask[sae.cfg.hook_name]\n",
    "            if mask_method == 'keep_only':\n",
    "                # any activations not in the mask are set to 0\n",
    "                expanded_circuit_mask = torch.zeros_like(feature_acts)\n",
    "                expanded_circuit_mask[:, :, mask_indices] = 1\n",
    "                feature_acts = feature_acts * expanded_circuit_mask\n",
    "            elif mask_method == 'zero_only':\n",
    "                feature_acts[:, :, mask_indices] = 0\n",
    "            else:\n",
    "                raise ValueError(f\"mask_method {mask_method} not recognized\")\n",
    "            \n",
    "        if cache_masked_activations:\n",
    "            sae.feature_acts = feature_acts.detach().clone()\n",
    "        if mean_ablate:\n",
    "            feature_acts = sae.mean_ablation\n",
    "\n",
    "        out = sae.decode(feature_acts)\n",
    "        # choose out or value based on the mask\n",
    "        mask_expanded = mask.unsqueeze(-1).expand_as(value)\n",
    "        value = torch.where(mask_expanded, out, value)\n",
    "        return value\n",
    "    return sae_hook\n",
    "\n",
    "\n",
    "    # def sae_hook_ablate(value, hook):\n",
    "    # feature_acts = sae.encode(value)\n",
    "    # # feature_acts[:, :, topsae_attr_indices] = 0\n",
    "    # out = sae.decode(feature_acts)\n",
    "    # return out\n",
    "\n",
    "\n",
    "def build_hooks_list(sequence,\n",
    "                    cache_sae_activations=False,\n",
    "                    cache_sae_grads=False,\n",
    "                    circuit_mask=None,\n",
    "                    use_mask=False,\n",
    "                    binarize_mask=False,\n",
    "                    mean_mask=False,\n",
    "                    cache_masked_activations=False,\n",
    "                    mean_ablate=False, # mean_ablate mean ablates the entire SAE regardless of the mask.\n",
    "                    ):\n",
    "    hooks = []\n",
    "    # blocks.0.hook_resid_pre\n",
    "    # # fake hook that adds zero so gradients propagate through the model\n",
    "    param = nn.Parameter(torch.tensor(0.0, requires_grad=True))\n",
    "    hooks.append(\n",
    "        (\n",
    "            \"blocks.0.hook_resid_pre\",\n",
    "            lambda value, hook: value + param,\n",
    "        )\n",
    "    )\n",
    "    for sae in saes:\n",
    "        hooks.append(\n",
    "            (\n",
    "            sae.cfg.hook_name,\n",
    "            build_sae_hook_fn(sae, sequence, cache_grads=cache_sae_grads, circuit_mask=circuit_mask, use_mask=use_mask, binarize_mask=binarize_mask, cache_masked_activations=cache_masked_activations, cache_sae_activations=cache_sae_activations, mean_mask=mean_mask, mean_ablate=mean_ablate),\n",
    "            )\n",
    "        )\n",
    "    return hooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_model_performance(logitfn):\n",
    "    baseline_dataset = ContrastiveDatasetBatch(json_dataset[-10:])\n",
    "    correct_logits = logitfn(baseline_dataset.correct_tokenized)\n",
    "    error_logits = logitfn(baseline_dataset.error_tokenized)\n",
    "    print(\"probability of predicting the correct age in the correct example\")\n",
    "    print(F.softmax(correct_logits[torch.arange(correct_logits.shape[0]), baseline_dataset.correct_answer_seq_idxs], dim=-1)[:, baseline_dataset.correct_token_idx].mean())\n",
    "    print(\"and of traceback in that example\")\n",
    "    print(F.softmax(correct_logits[torch.arange(correct_logits.shape[0]), baseline_dataset.correct_answer_seq_idxs], dim=-1)[:, baseline_dataset.error_token_idx].mean())\n",
    "    print(\"logit difference:\")\n",
    "    correct_logit_values = correct_logits[torch.arange(correct_logits.shape[0]), baseline_dataset.correct_answer_seq_idxs, baseline_dataset.correct_token_idx]\n",
    "    error_logit_values = correct_logits[torch.arange(correct_logits.shape[0]), baseline_dataset.correct_answer_seq_idxs, baseline_dataset.error_token_idx]\n",
    "    diff = correct_logit_values - error_logit_values\n",
    "    print(diff.mean())\n",
    "\n",
    "    print(\"probability of predicting the traceback in the error code example\")\n",
    "    print(F.softmax(error_logits[torch.arange(error_logits.shape[0]), baseline_dataset.error_answer_seq_idxs], dim=-1)[:, baseline_dataset.error_token_idx].mean())\n",
    "    print(\"and of the correct age in that example\")\n",
    "    print(F.softmax(error_logits[torch.arange(error_logits.shape[0]), baseline_dataset.error_answer_seq_idxs], dim=-1)[:, baseline_dataset.correct_token_idx].mean())    \n",
    "    print(\"logit difference:\")\n",
    "    correct_logit_values = error_logits[torch.arange(error_logits.shape[0]), baseline_dataset.error_answer_seq_idxs, baseline_dataset.error_token_idx]\n",
    "    error_logit_values = error_logits[torch.arange(error_logits.shape[0]), baseline_dataset.error_answer_seq_idxs, baseline_dataset.correct_token_idx]\n",
    "    diff = correct_logit_values - error_logit_values\n",
    "    print(diff.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_model_performance(logitfn):\n",
    "    baseline_dataset = ContrastiveDatasetBatch(json_dataset[-10:])\n",
    "    correct_logits = logitfn(baseline_dataset.correct_tokenized)\n",
    "    error_logits = logitfn(baseline_dataset.error_tokenized)\n",
    "    \n",
    "    # Initialize a results dictionary with shorter keys\n",
    "    results = {}\n",
    "    \n",
    "    # Compute probabilities for the correct example\n",
    "    correct_probs = F.softmax(\n",
    "        correct_logits[torch.arange(correct_logits.shape[0]), baseline_dataset.correct_answer_seq_idxs],\n",
    "        dim=-1\n",
    "    )\n",
    "    prob_correct_in_correct = correct_probs[:, baseline_dataset.correct_token_idx].mean().item()\n",
    "    prob_error_in_correct = correct_probs[:, baseline_dataset.error_token_idx].mean().item()\n",
    "    correct_logit_values = correct_logits[\n",
    "        torch.arange(correct_logits.shape[0]),\n",
    "        baseline_dataset.correct_answer_seq_idxs,\n",
    "        baseline_dataset.correct_token_idx\n",
    "    ]\n",
    "    error_logit_values = correct_logits[\n",
    "        torch.arange(correct_logits.shape[0]),\n",
    "        baseline_dataset.correct_answer_seq_idxs,\n",
    "        baseline_dataset.error_token_idx\n",
    "    ]\n",
    "    logit_diff_correct = (correct_logit_values - error_logit_values).mean().item()\n",
    "    \n",
    "    # Store results for the correct example\n",
    "    results['prob_correct_in_correct'] = prob_correct_in_correct\n",
    "    results['prob_error_in_correct'] = prob_error_in_correct\n",
    "    results['logit_diff_correct'] = logit_diff_correct\n",
    "    \n",
    "    # Compute probabilities for the error example\n",
    "    error_probs = F.softmax(\n",
    "        error_logits[torch.arange(error_logits.shape[0]), baseline_dataset.error_answer_seq_idxs],\n",
    "        dim=-1\n",
    "    )\n",
    "    prob_error_in_error = error_probs[:, baseline_dataset.error_token_idx].mean().item()\n",
    "    prob_correct_in_error = error_probs[:, baseline_dataset.correct_token_idx].mean().item()\n",
    "    correct_logit_values_error = error_logits[\n",
    "        torch.arange(error_logits.shape[0]),\n",
    "        baseline_dataset.error_answer_seq_idxs,\n",
    "        baseline_dataset.error_token_idx\n",
    "    ]\n",
    "    error_logit_values_error = error_logits[\n",
    "        torch.arange(error_logits.shape[0]),\n",
    "        baseline_dataset.error_answer_seq_idxs,\n",
    "        baseline_dataset.correct_token_idx\n",
    "    ]\n",
    "    logit_diff_error = (correct_logit_values_error - error_logit_values_error).mean().item()\n",
    "    \n",
    "    # Store results for the error example\n",
    "    results['prob_error_in_error'] = prob_error_in_error\n",
    "    results['prob_correct_in_error'] = prob_correct_in_error\n",
    "    results['logit_diff_error'] = logit_diff_error\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_contrastive_difference(logitfn):\n",
    "    baseline_dataset = ContrastiveDatasetBatch(json_dataset[0:10])\n",
    "    all_tokenized = baseline_dataset.all_tokenized\n",
    "    all_answer_seq_idxs = baseline_dataset.all_answer_seq_idxs\n",
    "    all_answers_tok_idxs = baseline_dataset.all_answers_tok_idxs\n",
    "    all_wrong_answers_tok_idxs = baseline_dataset.all_wrong_answers_tok_idxs\n",
    "    all_prompts = baseline_dataset.all_prompts\n",
    "    \n",
    "    all_logits = logitfn(all_tokenized)\n",
    "    all_answer_logits = all_logits[torch.arange(all_logits.shape[0]), all_answer_seq_idxs]\n",
    "    all_answers_correct_logits = all_answer_logits[torch.arange(all_answer_logits.shape[0]), all_answers_tok_idxs]\n",
    "    all_answers_wrong_logits = all_answer_logits[torch.arange(all_answer_logits.shape[0]), all_wrong_answers_tok_idxs]\n",
    "    all_logit_diffs = all_answers_correct_logits - all_answers_wrong_logits\n",
    "    # 6.7 dif for correct, 1.8 for error\n",
    "    all_logit_diffs[0:baseline_dataset.batch_size] = all_logit_diffs[0:baseline_dataset.batch_size]/6.7\n",
    "    all_logit_diffs[baseline_dataset.batch_size:] = all_logit_diffs[baseline_dataset.batch_size:]/1.8\n",
    "    return all_logit_diffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE vs no SAE (sanity check and basic setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dataset = ContrastiveDatasetBatch(json_dataset[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_logit_fn(tokens):\n",
    "    correct_logits = model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=[\n",
    "            #(\n",
    "            #utils.get_act_name(\"pre\", 0), # v=attention out\n",
    "            #\"blocks.0.hook_mlp_out\",\n",
    "            #mlp_ablation_hook,\n",
    "            #),\n",
    "            ]\n",
    "        )\n",
    "    return correct_logits\n",
    "\n",
    "with torch.no_grad():\n",
    "    sanity_check_model_performance(baseline_model_logit_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_id\n",
    "bos_token_id = model.tokenizer.bos_token_id\n",
    "bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def logitfn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens)\n",
    "            )\n",
    "    sanity_check_model_performance(logitfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def logitfn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens)\n",
    "            )\n",
    "    logits = logitfn(baseline_dataset.error_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>>>', 'Traceback', 'print']\n",
      "tensor([25.8636, 25.4394, 24.8588], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(24.1308, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 4\n",
    "topk = torch.topk(logits[:, -1, :][test_idx], k=3)\n",
    "print(model.to_str_tokens(topk.indices))\n",
    "print(topk.values)\n",
    "logits[:, -1, :][test_idx][baseline_dataset.correct_token_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Logit Diff With Positive and Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0415, 0.9522, 1.0375, 1.1017, 1.0306, 1.0303, 1.0525, 0.9940, 1.1501,\n",
      "        0.9840, 0.8197, 1.1012, 1.5776, 0.9999, 1.5780, 0.8209, 0.8822, 1.0724,\n",
      "        1.4219, 1.0966], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    def logitfn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens)\n",
    "            )\n",
    "    all_logit_diffs = all_contrastive_difference(logitfn)\n",
    "    print(all_logit_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitfn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, cache_sae_grads=True)\n",
    "        )\n",
    "\n",
    "all_logit_diffs = all_contrastive_difference(logitfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = all_logit_diffs.sum() * -1 # maximize the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-21.7448, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ablate = {\"mask_method\": \"keep_only\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = saes[0].cfg.d_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for sae in saes:\n",
    "        delta_loss = torch.abs((sae.feature_acts.grad * sae.feature_acts).view(-1, sae.feature_acts.shape[-1]).sum(dim=0))\n",
    "        topk = torch.topk(delta_loss, k=63)\n",
    "        no_ablate[sae.cfg.hook_name] = topk.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# deep copy\n",
    "import copy\n",
    "random_ablate = copy.deepcopy(no_ablate)\n",
    "\n",
    "num_features = saes[0].cfg.d_sae\n",
    "\n",
    "for key in random_ablate.keys():\n",
    "    if key == \"mask_method\":\n",
    "        continue\n",
    "#     for i in range(len(random_ablate[key])):\n",
    "#         random_ablate[key][i] = random.randint(0, num_features-1)\n",
    "# random_ablate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the ablation\n",
    "    \n",
    "with torch.no_grad():\n",
    "    def logitfn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(\n",
    "                tokens,\n",
    "                cache_sae_grads=False,\n",
    "                circuit_mask=no_ablate)\n",
    "            )\n",
    "    \n",
    "    all_logit_diffs = sanity_check_model_performance(logitfn)\n",
    "    #all_logit_diffs = san(logitfn).mean()\n",
    "    # print(all_logit_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect SAE Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each SAE create a sae_dim float32 with mean latent activation over subset of datset\n",
    "batch_size = 16\n",
    "num_batches = 10\n",
    "num_features = saes[0].cfg.d_sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Accum Progress: 801it [01:59,  6.68it/s]                         \n"
     ]
    }
   ],
   "source": [
    "def logitfn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, cache_sae_activations=True)\n",
    "        )\n",
    "\n",
    "def running_mean_tensor(old_mean, new_value, n):\n",
    "    return old_mean + (new_value - old_mean) / n\n",
    "\n",
    "# # test running mean tensor\n",
    "# test_data = torch.arange(3).float()\n",
    "# test_data\n",
    "\n",
    "# data_examples = []\n",
    "# for i in range(30):\n",
    "#     # add noise to the data\n",
    "#     data_examples.append(test_data + torch.randn_like(test_data)*0.1)\n",
    "\n",
    "# running_mean = torch.zeros_like(test_data)\n",
    "# for i, data in enumerate(data_examples):\n",
    "#     running_mean = running_mean_tensor(running_mean, data, i+1)\n",
    "#     print(running_mean)\n",
    "\n",
    "tok1 = traceback_token\n",
    "tok2 = answer_token\n",
    "\n",
    "\n",
    "all_fwd_passes = []\n",
    "def get_sae_means(total_steps, per_token_mask=False, keep_only='none'):\n",
    "    all_optimized_params = []\n",
    "    for sae in saes:\n",
    "        sae.mean_ablation = torch.zeros(sae.cfg.d_sae).float()\n",
    "    \n",
    "    with tqdm.tqdm(total=total_steps, desc=\"Mean Accum Progress\") as pbar:\n",
    "        for i, (x, y) in enumerate(zip(simple_dataset, simple_labels)):\n",
    "            if keep_only == 'traceback' and y != traceback_token:\n",
    "                continue\n",
    "            if keep_only == 'correct' and y != answer_token:\n",
    "                continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = logitfn(x)\n",
    "                for sae in saes:\n",
    "                    sae.mean_ablation = running_mean_tensor(sae.mean_ablation, sae.feature_acts, i+1)\n",
    "            pbar.update(1)\n",
    "\n",
    "            if i >= total_steps:\n",
    "                break\n",
    "\n",
    "get_sae_means(50*16, keep_only='none')\n",
    "\n",
    "\n",
    "# # this won't work anymore b/c I removed mean_ablate\n",
    "# def mean_ablated_logitfn(tokens):\n",
    "#     return model.run_with_hooks(\n",
    "#         tokens, \n",
    "#         return_type=\"logits\", \n",
    "#         fwd_hooks=build_hooks_list(tokens, mean_ablate=True)\n",
    "#         )\n",
    "\n",
    "# # all_contrastive_difference\n",
    "# sanity_check_model_performance(mean_ablated_logitfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sae in saes:\n",
    "    sae.mean_ablation = sae.mean_ablation.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jatin's code for mean ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean Accum Progress: 51it [00:38,  1.33it/s]                        \n"
     ]
    }
   ],
   "source": [
    "clean_dataset = []\n",
    "corr_dataset = []\n",
    "clean_labels = []\n",
    "corr_labels = []\n",
    "\n",
    "answer_token = model.to_single_token(\"1\")\n",
    "traceback_token = model.to_single_token(\"Traceback\")\n",
    "\n",
    "for item in json_dataset:\n",
    "    clean_dataset.append(item[\"error\"][\"prompt\"])\n",
    "    corr_dataset.append(item[\"correct\"][\"prompt\"])\n",
    "    clean_labels.append(traceback_token)\n",
    "    corr_labels.append(answer_token)\n",
    "\n",
    "\n",
    "clean_tok_dataset = model.to_tokens(clean_dataset)\n",
    "clean_labels = torch.tensor(clean_labels)\n",
    "\n",
    "corr_tok_dataset = model.to_tokens(corr_dataset)\n",
    "corr_labels = torch.tensor(corr_labels)\n",
    "\n",
    "permutation = torch.randperm(len(clean_tok_dataset))\n",
    "clean_tok_dataset = clean_tok_dataset[permutation]\n",
    "clean_labels = clean_labels[permutation]\n",
    "\n",
    "corr_tok_dataset = corr_tok_dataset[permutation]\n",
    "corr_labels = corr_labels[permutation]\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "def running_mean_tensor(old_mean, new_value, n):\n",
    "    \"\"\"Update the running mean tensor using the current batch.\"\"\"\n",
    "    return old_mean + (new_value - old_mean) / n\n",
    "def get_sae_means(saes, dataset, total_steps, batch_size=16):\n",
    "    \"\"\"\n",
    "    Compute token-level means across the dataset in a batched manner.\n",
    "    Args:\n",
    "        dataset (Tensor): The input dataset of tokenized data.\n",
    "        total_steps (int): Number of steps to process.\n",
    "        batch_size (int): Number of examples per batch.\n",
    "    \"\"\"\n",
    "    for sae in saes:\n",
    "        # Initialize mean_ablation with correct shape\n",
    "        sae.mean_ablation = torch.zeros((dataset[0].shape[0], sae.cfg.d_sae)).float().to(device)\n",
    "    total_samples = len(dataset)\n",
    "    num_batches = (total_samples + batch_size - 1) // batch_size  # Calculate number of batches\n",
    "    with tqdm(total=min(total_steps, num_batches), desc=\"Mean Accum Progress\") as pbar:\n",
    "        sample_count = 0  # To track total number of samples processed\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            # Batch selection\n",
    "            batch_x = dataset[i:i+batch_size]\n",
    "            with torch.no_grad():\n",
    "                logits = logitfn(batch_x)  # Get logits (forward pass)\n",
    "                for sae in saes:\n",
    "                    # Compute batch mean over tokens\n",
    "                    batch_mean = sae.feature_acts.mean(dim=0)  # Mean across the batch\n",
    "                    sample_count +=  1 # len(batch_x)  # Update sample count\n",
    "                    # Update running mean tensor\n",
    "                    sae.mean_ablation = running_mean_tensor(\n",
    "                        sae.mean_ablation,\n",
    "                        batch_mean,\n",
    "                        sample_count\n",
    "                    )\n",
    "            pbar.update(1)  # Update progress bar\n",
    "            # Stop if we've processed enough steps\n",
    "            if i // batch_size >= total_steps:\n",
    "                break\n",
    "\n",
    "get_sae_means(saes, corr_tok_dataset, 50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 16384])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saes[0].mean_ablation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob_correct_in_correct': 0.9518125653266907,\n",
       " 'prob_error_in_correct': 0.00013982107338961214,\n",
       " 'logit_diff_correct': 8.825759887695312,\n",
       " 'prob_error_in_error': 0.00013982107338961214,\n",
       " 'prob_correct_in_error': 0.9518125653266907,\n",
       " 'logit_diff_error': -8.825759887695312}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: If you run the rest of the code it adds a batch dim to this data, and this code is screwed\n",
    "def mean_ablated_logitfn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, mean_ablate=True)\n",
    "        )\n",
    "\n",
    "# all_contrastive_difference\n",
    "sanity_check_model_performance(mean_ablated_logitfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Binary Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# makethe length of the dataset a multiple of the batch size\n",
    "simple_dataset = simple_dataset[:batch_size*(len(simple_dataset)//batch_size)]\n",
    "simple_labels = simple_labels[:batch_size*(len(simple_labels)//batch_size)]\n",
    "\n",
    "simple_dataset = simple_dataset.view(-1, batch_size, 65)\n",
    "simple_labels = simple_labels.view(-1, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitfn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, use_mask=True, mean_mask=True)\n",
    "        )\n",
    "\n",
    "\n",
    "def forward_pass(batch, labels, logitfn, ratio_trained=1):\n",
    "    for sae in saes:\n",
    "        sae.mask.ratio_trained = ratio_trained\n",
    "    tokens = batch\n",
    "    logits = logitfn(tokens)\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    loss = F.cross_entropy(last_token_logits, labels)\n",
    "    sparsity_loss = 0\n",
    "    for sae in saes:\n",
    "        sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "    \n",
    "    sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "    return loss, sparsity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def do_training_run(sparsity_multiplier, per_token_mask=False, use_mask=False, mean_mask=False):\n",
    "\n",
    "    def logitfn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens, use_mask=use_mask, mean_mask=mean_mask)\n",
    "            )\n",
    "\n",
    "    def forward_pass(batch, labels, logitfn, ratio_trained=1):\n",
    "        for sae in saes:\n",
    "            sae.mask.ratio_trained = ratio_trained\n",
    "        tokens = batch\n",
    "        logits = logitfn(tokens)\n",
    "        last_token_logits = logits[:, -1, :]\n",
    "        loss = F.cross_entropy(last_token_logits, labels)\n",
    "        sparsity_loss = 0\n",
    "        for sae in saes:\n",
    "            sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "        \n",
    "        sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "        return loss, sparsity_loss\n",
    "\n",
    "    print(\"doing a run with sparsity multiplier\", sparsity_multiplier)\n",
    "    all_optimized_params = []\n",
    "    config = {\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"total_steps\": simple_dataset.shape[0]*0.01,\n",
    "        \"sparsity_multiplier\": sparsity_multiplier\n",
    "    }\n",
    "\n",
    "    for sae in saes:\n",
    "        if per_token_mask:\n",
    "            sae.mask = SparseMask(sae.cfg.d_sae, 1.0, seq_len=65)\n",
    "        else:\n",
    "            sae.mask = SparseMask(sae.cfg.d_sae, 1.0)\n",
    "        all_optimized_params.extend(list(sae.mask.parameters()))\n",
    "        sae.mask.max_temp = torch.tensor(200.0)\n",
    "    \n",
    "    wandb.init(project=\"sae circuits\", config=config)\n",
    "    optimizer = optim.Adam(all_optimized_params, lr=config[\"learning_rate\"])\n",
    "    total_steps = config[\"total_steps\"]\n",
    "\n",
    "    with tqdm(total=total_steps, desc=\"Training Progress\") as pbar:\n",
    "        for i, (x, y) in enumerate(zip(simple_dataset, simple_labels)):\n",
    "            with KeyboardInterruptBlocker():\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Calculate ratio trained\n",
    "                ratio_trained = i / total_steps\n",
    "                \n",
    "                # Update mask ratio for each SAE\n",
    "                for sae in saes:\n",
    "                    sae.mask.ratio_trained = ratio_trained\n",
    "                \n",
    "                # Forward pass with updated ratio_trained\n",
    "                loss, sparsity_loss = forward_pass(x, y, logitfn, ratio_trained=ratio_trained)\n",
    "                if per_token_mask:\n",
    "                    sparsity_loss = sparsity_loss / 65\n",
    "\n",
    "                avg_nonzero_elements = sparsity_loss\n",
    "                    \n",
    "                sparsity_loss = sparsity_loss * config[\"sparsity_multiplier\"]\n",
    "                total_loss = loss + sparsity_loss\n",
    "                infodict  = {\"Step\": i, \"Progress\": ratio_trained, \"Avg Nonzero Elements\": avg_nonzero_elements.item(), \"Task Loss\": loss.item(), \"Sparsity Loss\": sparsity_loss.item(), \"temperature\": saes[0].mask.temperature}\n",
    "                wandb.log(infodict)\n",
    "                \n",
    "                # Backward pass and optimizer step\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update tqdm bar with relevant metrics\n",
    "                pbar.set_postfix(infodict)\n",
    "                \n",
    "                # Update the tqdm progress bar\n",
    "                pbar.update(1)\n",
    "                if i >= total_steps*1.3:\n",
    "                    break\n",
    "    wandb.finish()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for sae in saes:\n",
    "        for param in sae.parameters():\n",
    "            param.grad = None\n",
    "        for param in sae.mask.parameters():\n",
    "            param.grad = None\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.grad = None\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    mask_dict = {}\n",
    "\n",
    "    total_density = 0\n",
    "    for sae in saes:\n",
    "        mask_dict[sae.cfg.hook_name] = torch.where(torch.sigmoid(sae.mask.mask*10000))[0].tolist()\n",
    "        total_density += torch.sigmoid(sae.mask.mask*10000).sum().item()\n",
    "    mask_dict[\"total_density\"] = total_density\n",
    "    mask_dict['avg_density'] = total_density / len(saes)\n",
    "    print(mask_dict['avg_density'])\n",
    "\n",
    "    ### EVAL ###\n",
    "    def masked_logit_fn(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens, use_mask=use_mask, mean_mask=mean_mask, binarize_mask=True)\n",
    "            )\n",
    "\n",
    "    def eval_ce_loss(batch, labels, logitfn, ratio_trained=10):\n",
    "        for sae in saes:\n",
    "            sae.mask.ratio_trained = ratio_trained\n",
    "        tokens = batch\n",
    "        logits = logitfn(tokens)\n",
    "        last_token_logits = logits[:, -1, :]\n",
    "        loss = F.cross_entropy(last_token_logits, labels)\n",
    "\n",
    "        # sparsity_loss = 0\n",
    "        # for sae in saes:\n",
    "        #     sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "        \n",
    "        # sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], masked_logit_fn)\n",
    "        print(\"CE loss:\", loss)\n",
    "\n",
    "    mask_dict['ce_loss'] = loss.item()\n",
    "\n",
    "\n",
    "    json.dump(mask_dict, open(f\"{str(sparsity_multiplier)}_run.json\", \"w\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE loss: tensor(18.4099, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def masked_logit_fn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, use_mask=True, mean_mask=True, binarize_mask=True)\n",
    "        )\n",
    "\n",
    "def eval_ce_loss(batch, labels, logitfn, ratio_trained=10):\n",
    "    for sae in saes:\n",
    "        sae.mask.ratio_trained = ratio_trained\n",
    "    tokens = batch\n",
    "    logits = logitfn(tokens)\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    loss = F.cross_entropy(last_token_logits, labels)\n",
    "\n",
    "    # sparsity_loss = 0\n",
    "    # for sae in saes:\n",
    "    #     sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "    \n",
    "    # sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "    return loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = eval_ce_loss(simple_dataset[30], simple_labels[30], masked_logit_fn)\n",
    "    print(\"CE loss:\", loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjcaples4\u001b[0m (\u001b[33mllm-research-activated\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing a run with sparsity multiplier 0.025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/lowrank/wandb/run-20241208_231121-kvogk8cf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llm-research-activated/sae%20circuits/runs/kvogk8cf' target=\"_blank\">copper-wave-68</a></strong> to <a href='https://wandb.ai/llm-research-activated/sae%20circuits' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llm-research-activated/sae%20circuits' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llm-research-activated/sae%20circuits/runs/kvogk8cf' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits/runs/kvogk8cf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  99%|| 124/124.96000000000001 [03:29<00:01,  1.69s/it, Step=124, Progress=0.992, Avg Nonzero Elements=117, Task Loss=0.503, Sparsity Loss=2.92, temperature=tensor(192.0226, device='cuda:0')]/usr/local/lib/python3.10/dist-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "Training Progress: 164it [04:34,  1.68s/it, Step=163, Progress=1.3, Avg Nonzero Elements=117, Task Loss=0.589, Sparsity Loss=2.92, temperature=tensor(1003.4679, device='cuda:0')]                                         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg Nonzero Elements</td><td></td></tr><tr><td>Progress</td><td></td></tr><tr><td>Sparsity Loss</td><td></td></tr><tr><td>Step</td><td></td></tr><tr><td>Task Loss</td><td></td></tr><tr><td>temperature</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg Nonzero Elements</td><td>116.75</td></tr><tr><td>Progress</td><td>1.30442</td></tr><tr><td>Sparsity Loss</td><td>2.91875</td></tr><tr><td>Step</td><td>163</td></tr><tr><td>Task Loss</td><td>0.5887</td></tr><tr><td>temperature</td><td>1003.4679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-wave-68</strong> at: <a href='https://wandb.ai/llm-research-activated/sae%20circuits/runs/kvogk8cf' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits/runs/kvogk8cf</a><br/> View project at: <a href='https://wandb.ai/llm-research-activated/sae%20circuits' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241208_231121-kvogk8cf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.75\n",
      "CE loss: tensor(0.5731, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "do_training_run(0.025, per_token_mask=False, use_mask=True, mean_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original example\n",
      "<bos>Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> age = {'Liam': 17, 'Emily': 17, 'Mia': 17, 'Sophia': 17, 'Ethan': 11}\n",
      ">>> age[\"Liam\"]\n",
      "\n",
      "original label\n",
      "1\n",
      "torch.Size([256000])\n",
      "torch.Size([256000])\n",
      "['1', 'Traceback', '>>>']\n",
      "tensor([0.6384, 0.2210, 0.0217], device='cuda:0')\n",
      "ce loss 0.44883954524993896\n"
     ]
    }
   ],
   "source": [
    "def logitfn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, use_mask=True, mean_mask=True, binarize_mask=True)\n",
    "        )\n",
    "\n",
    "# def forward_pass(batch, labels, logitfn, ratio_trained=1):\n",
    "#     for sae in saes:\n",
    "#         sae.mask.ratio_trained = ratio_trained\n",
    "#     tokens = batch\n",
    "#     logits = logitfn(tokens)\n",
    "#     last_token_logits = logits[:, -1, :]\n",
    "#     loss = F.cross_entropy(last_token_logits, labels)\n",
    "#     sparsity_loss = 0\n",
    "#     for sae in saes:\n",
    "#         sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "    \n",
    "#     sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "    return loss, sparsity_loss\n",
    "with torch.no_grad():\n",
    "    idx = 4\n",
    "    print(\"original example\")\n",
    "    print(f\"{model.to_string(simple_dataset[-1][idx])}\")\n",
    "    print(\"original label\")\n",
    "    print(model.to_string(simple_labels[-1][idx:idx+1]))\n",
    "    logits = logitfn(simple_dataset[-1][idx:idx+1][-1])[-1][-1]\n",
    "    print(logits.shape)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    print(probs.shape)\n",
    "    # get the top 3 tokens and their probabilities\n",
    "    topk = torch.topk(probs, k=3)\n",
    "    print(model.to_str_tokens(topk.indices))\n",
    "    print(topk.values)\n",
    "    # get the cross entropy loss\n",
    "    loss = F.cross_entropy(logits.unsqueeze(0), simple_labels[-1][idx:idx+1])\n",
    "    print(f\"ce loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n",
      "Token 0: <bos> 0\n",
      "Token 1: Type 0\n",
      "Token 2:  \" 0\n",
      "Token 3: help 0\n",
      "Token 4: \", 0\n",
      "Token 5:  \" 0\n",
      "Token 6: copyright 0\n",
      "Token 7: \", 0\n",
      "Token 8:  \" 0\n",
      "Token 9: credits 0\n",
      "Token 10: \" 0\n",
      "Token 11:  or 0\n",
      "Token 12:  \" 0\n",
      "Token 13: license 0\n",
      "Token 14: \" 0\n",
      "Token 15:  for 0\n",
      "Token 16:  more 0\n",
      "Token 17:  information 0\n",
      "Token 18: . 0\n",
      "Token 19: \n",
      " 0\n",
      "Token 20: >>> 0\n",
      "Token 21:  age 0\n",
      "Token 22:  = 0\n",
      "Token 23:  {' 0\n",
      "Token 24: Olivia 0\n",
      "Token 25: ': 0\n",
      "Token 26:   0\n",
      "Token 27: 1 0\n",
      "Token 28: 8 0\n",
      "Token 29: , 0\n",
      "Token 30:  ' 0\n",
      "Token 31: Sophia 0\n",
      "Token 32: ': 0\n",
      "Token 33:   0\n",
      "Token 34: 1 0\n",
      "Token 35: 4 0\n",
      "Token 36: , 0\n",
      "Token 37:  ' 0\n",
      "Token 38: Ava 0\n",
      "Token 39: ': 0\n",
      "Token 40:   0\n",
      "Token 41: 1 0\n",
      "Token 42: 8 0\n",
      "Token 43: , 0\n",
      "Token 44:  ' 0\n",
      "Token 45: Emma 0\n",
      "Token 46: ': 0\n",
      "Token 47:   0\n",
      "Token 48: 1 0\n",
      "Token 49: 7 0\n",
      "Token 50: , 0\n",
      "Token 51:  ' 0\n",
      "Token 52: Oliver 0\n",
      "Token 53: ': 0\n",
      "Token 54:   0\n",
      "Token 55: 1 0\n",
      "Token 56: 1 0\n",
      "Token 57: } 0\n",
      "Token 58: \n",
      " 0\n",
      "Token 59: >>> 0\n",
      "Token 60:  age 0\n",
      "Token 61: [\" 0\n",
      "Token 62: Chris 0\n",
      "Token 63: \"] 0\n",
      "Token 64: \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# ?????\n",
    "# testmask = saes[0].mask.mask.data.clone()\n",
    "\n",
    "# binarized = (testmask > 0.5).float()\n",
    "\n",
    "# print(torch.count_nonzero(binarized))\n",
    "\n",
    "# tokens = model.to_str_tokens(simple_dataset[2][0])\n",
    "# for i in range(65):\n",
    "#     print(f\"Token {i}:\", tokens[i], torch.count_nonzero(binarized[i]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'saes', 'model', and 'simple_dataset' are defined\n",
    "tokens = model.to_str_tokens(simple_dataset[2][0])\n",
    "num_masks = 4  # Number of masks you have\n",
    "counts_per_mask = []\n",
    "\n",
    "for mask_index in range(num_masks):\n",
    "    testmask = saes[mask_index].mask.mask.data.clone()\n",
    "    binarized = (testmask > 0.5).float()\n",
    "    counts = []\n",
    "    for i in range(len(tokens)):\n",
    "        counts.append(torch.count_nonzero(binarized[i]).item())\n",
    "    counts_per_mask.append(counts)\n",
    "\n",
    "# Convert counts to a NumPy array\n",
    "data = np.array(counts_per_mask)  # Shape: (num_masks, num_tokens)\n",
    "\n",
    "# Create a mask for zero values\n",
    "zero_mask = data == 0\n",
    "\n",
    "# Create a custom colormap that starts from a color for the lowest non-zero value\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define a colormap\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "# Plot the heatmap with the mask\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.heatmap(\n",
    "    data,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=cmap,\n",
    "    mask=zero_mask,\n",
    "    cbar_kws={'label': 'Counts'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray'\n",
    ")\n",
    "\n",
    "# Set x-axis labels to tokens\n",
    "ax.set_xticks(np.arange(len(tokens)) + 0.5)\n",
    "ax.set_xticklabels(tokens, rotation=90, fontsize=8)\n",
    "\n",
    "# Set y-axis labels to masks\n",
    "ax.set_yticks(np.arange(num_masks) + 0.5)\n",
    "ax.set_yticklabels([f'SAE {i}' for i in range(num_masks)], rotation=0)\n",
    "\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('SAE Number Active Latents')\n",
    "plt.title('Active SAE Latents per Token per Mask (Zero Counts Hidden)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Positions of the tokens on the x-axis\n",
    "x = np.arange(len(tokens))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot counts for each mask\n",
    "for mask_index in range(num_masks):\n",
    "    y = counts_per_mask[mask_index]\n",
    "    plt.plot(x, y, marker='o', label=f'Mask {mask_index}')\n",
    "\n",
    "# Set x-axis labels to tokens\n",
    "plt.xticks(x, tokens, rotation=90, fontsize=8)\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Unmasked latents per Token for Each Mask')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>',\n",
       " 'Type',\n",
       " ' \"',\n",
       " 'help',\n",
       " '\",',\n",
       " ' \"',\n",
       " 'copyright',\n",
       " '\",',\n",
       " ' \"',\n",
       " 'credits',\n",
       " '\"',\n",
       " ' or',\n",
       " ' \"',\n",
       " 'license',\n",
       " '\"',\n",
       " ' for',\n",
       " ' more',\n",
       " ' information',\n",
       " '.',\n",
       " '\\n',\n",
       " '>>>',\n",
       " ' age',\n",
       " ' =',\n",
       " \" {'\",\n",
       " 'Lucas',\n",
       " \"':\",\n",
       " ' ',\n",
       " '1',\n",
       " '5',\n",
       " ',',\n",
       " \" '\",\n",
       " 'James',\n",
       " \"':\",\n",
       " ' ',\n",
       " '1',\n",
       " '6',\n",
       " ',',\n",
       " \" '\",\n",
       " 'Megan',\n",
       " \"':\",\n",
       " ' ',\n",
       " '1',\n",
       " '1',\n",
       " ',',\n",
       " \" '\",\n",
       " 'Emma',\n",
       " \"':\",\n",
       " ' ',\n",
       " '1',\n",
       " '7',\n",
       " ',',\n",
       " \" '\",\n",
       " 'Oliver',\n",
       " \"':\",\n",
       " ' ',\n",
       " '1',\n",
       " '3',\n",
       " '}',\n",
       " '\\n',\n",
       " '>>>',\n",
       " ' age',\n",
       " '[\"',\n",
       " 'Benjamin',\n",
       " '\"]',\n",
       " '\\n']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3649, -1.3649, -1.3649,  ..., -1.3649, -1.3649, -1.3649],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(saes[0].mask.mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sae in saes:\n",
    "    for param in sae.parameters():\n",
    "        param.grad = None\n",
    "    for param in sae.mask.parameters():\n",
    "        param.grad = None\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.grad = None\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPRAM sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with sparsity multiplier 0.06666666666666667\n",
      "doing a run with sparsity multiplier 0.06666666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/lowrank/wandb/run-20241101_052323-f5xclrxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llm-research-activated/sae%20circuits/runs/f5xclrxs' target=\"_blank\">thriving-sparkler-50</a></strong> to <a href='https://wandb.ai/llm-research-activated/sae%20circuits' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llm-research-activated/sae%20circuits' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llm-research-activated/sae%20circuits/runs/f5xclrxs' target=\"_blank\">https://wandb.ai/llm-research-activated/sae%20circuits/runs/f5xclrxs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|         | 6/125.0 [00:10<03:28,  1.75s/it, Step=5, Progress=0.04, Avg Nonzero Elements=1.17e+4, Task Loss=5.53, Sparsity Loss=783, temperature=tensor(1.2361, device='cuda:0')] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m sparsity_multiplier \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39mstep\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting run with sparsity multiplier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparsity_multiplier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdo_training_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparsity_multiplier\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 42\u001b[0m, in \u001b[0;36mdo_training_run\u001b[0;34m(sparsity_multiplier, per_token_mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m     sae\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mratio_trained \u001b[38;5;241m=\u001b[39m ratio_trained\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Forward pass with updated ratio_trained\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m loss, sparsity_loss \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogitfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio_trained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratio_trained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m per_token_mask:\n\u001b[1;32m     44\u001b[0m     sparsity_loss \u001b[38;5;241m=\u001b[39m sparsity_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m65\u001b[39m\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(batch, labels, logitfn, ratio_trained)\u001b[0m\n\u001b[1;32m     11\u001b[0m     sae\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mratio_trained \u001b[38;5;241m=\u001b[39m ratio_trained\n\u001b[1;32m     12\u001b[0m tokens \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 13\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogitfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m last_token_logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(last_token_logits, labels)\n",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m, in \u001b[0;36mlogitfn\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogitfn\u001b[39m(tokens):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_hooks_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py:454\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py:573\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    570\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 573\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    154\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    156\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/abstract_attention.py:209\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpositional_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    207\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_rot_q(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_rotary(q, kv_cache_pos_offset, attention_mask))\n\u001b[1;32m    208\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_rot_k(\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_rotary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     )  \u001b[38;5;66;03m# keys are cached so no offset\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mfloat32, torch\u001b[38;5;241m.\u001b[39mfloat64]:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# If using 16 bits, increase the precision to avoid numerical instabilities\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/abstract_attention.py:565\u001b[0m, in \u001b[0;36mAbstractAttention.apply_rotary\u001b[0;34m(self, x, past_kv_pos_offset, attention_mask)\u001b[0m\n\u001b[1;32m    562\u001b[0m     mask_rotary_sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_sin[offset_position_ids, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m    563\u001b[0m     x_rotated \u001b[38;5;241m=\u001b[39m x_rot \u001b[38;5;241m*\u001b[39m mask_rotary_cos \u001b[38;5;241m+\u001b[39m x_flip \u001b[38;5;241m*\u001b[39m mask_rotary_sin\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_rotated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pass\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1/10 -> 1/100\n",
    "num_runs = 10\n",
    "\n",
    "start = 1/15\n",
    "end = 1/100\n",
    "step = (end-start)/num_runs\n",
    "\n",
    "for i in range(num_runs):\n",
    "    sparsity_multiplier = start + i*step\n",
    "    print(f\"Starting run with sparsity multiplier {sparsity_multiplier}\")\n",
    "    do_training_run(sparsity_multiplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_logit_fn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens, use_mask=True, binarize_mask=True, mean_mask=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_logit_fn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_sae_logit_fn(tokens):\n",
    "    return model.run_with_hooks(\n",
    "        tokens, \n",
    "        return_type=\"logits\", \n",
    "        fwd_hooks=build_hooks_list(tokens)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# serialize the masks\n",
    "mask_dict = {}\n",
    "for sae in saes:\n",
    "    mask_dict[sae.cfg.hook_name] = torch.where(torch.sigmoid(sae.mask.mask*10000))[0].tolist()\n",
    "\n",
    "json.dump(mask_dict, open(\"mask_dict.json\", \"w\"))\n",
    "len(mask_dict[\"blocks.7.hook_resid_post\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonzero elements in mask for blocks.7.hook_resid_post: 5\n",
      "Nonzero elements in mask for blocks.14.hook_resid_post: 13\n",
      "Nonzero elements in mask for blocks.21.hook_resid_post: 20\n",
      "Nonzero elements in mask for blocks.40.hook_resid_post: 45\n"
     ]
    }
   ],
   "source": [
    "for sae in saes:\n",
    "    mask = sae.mask.mask\n",
    "    print(f\"Nonzero elements in mask for {sae.cfg.hook_name}: {torch.count_nonzero(torch.sigmoid(mask*1000))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss: tensor(0.0276, device='cuda:0')\n",
      "sae loss:  tensor(0.8250, device='cuda:0')\n",
      "ablated loss:  tensor(0.4248, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def eval_ce_loss(batch, labels, logitfn, ratio_trained=10):\n",
    "    for sae in saes:\n",
    "        sae.mask.ratio_trained = ratio_trained\n",
    "    tokens = batch\n",
    "    logits = logitfn(tokens)\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    loss = F.cross_entropy(last_token_logits, labels)\n",
    "    sparsity_loss = 0\n",
    "    for sae in saes:\n",
    "        sparsity_loss = sparsity_loss + sae.mask.sparsity_loss\n",
    "    \n",
    "    sparsity_loss = sparsity_loss / len(saes)\n",
    "\n",
    "    return loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], baseline_logit_fn)\n",
    "    print(\"baseline loss:\", loss)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], baseline_sae_logit_fn)\n",
    "    print(\"sae loss: \", loss)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], masked_logit_fn)\n",
    "    print(\"ablated loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ce_loss(batch, labels, logitfn, ratio_trained=10):\n",
    "    # Assuming 'saes' is defined elsewhere in your code\n",
    "    for sae in saes:\n",
    "        sae.mask.ratio_trained = ratio_trained\n",
    "    tokens = batch\n",
    "    logits = logitfn(tokens)\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    loss = F.cross_entropy(last_token_logits, labels)\n",
    "    sparsity_loss = 0\n",
    "    for sae in saes:\n",
    "        sparsity_loss += sae.mask.sparsity_loss\n",
    "    \n",
    "    sparsity_loss = sparsity_loss / len(saes)\n",
    "    total_loss = loss + sparsity_loss\n",
    "\n",
    "    return loss.item()  # Return the loss as a scalar value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(Age|Correct Ex)</th>\n",
       "      <th>P(Traceback|Correct Ex)</th>\n",
       "      <th>Logit Diff (Correct Ex)</th>\n",
       "      <th>P(Traceback|Error Ex)</th>\n",
       "      <th>P(Age|Error Ex)</th>\n",
       "      <th>Logit Diff (Error Ex)</th>\n",
       "      <th>Cross-Entropy Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VANILLA GEMMA 9B</th>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>6.898462</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.925329</td>\n",
       "      <td>0.027596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEMMA 9B WITH SAE (no masks)</th>\n",
       "      <td>0.929262</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>6.914926</td>\n",
       "      <td>0.176590</td>\n",
       "      <td>0.025586</td>\n",
       "      <td>2.025202</td>\n",
       "      <td>0.825018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEMMA 9B WITH SAE Masked</th>\n",
       "      <td>0.828356</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>4.076188</td>\n",
       "      <td>0.469673</td>\n",
       "      <td>0.076615</td>\n",
       "      <td>1.813243</td>\n",
       "      <td>0.424774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              P(Age|Correct Ex)  P(Traceback|Correct Ex)  \\\n",
       "method                                                                     \n",
       "VANILLA GEMMA 9B                       0.979983                 0.001325   \n",
       "GEMMA 9B WITH SAE (no masks)           0.929262                 0.001051   \n",
       "GEMMA 9B WITH SAE Masked               0.828356                 0.015461   \n",
       "\n",
       "                              Logit Diff (Correct Ex)  P(Traceback|Error Ex)  \\\n",
       "method                                                                         \n",
       "VANILLA GEMMA 9B                             6.898462               0.959781   \n",
       "GEMMA 9B WITH SAE (no masks)                 6.914926               0.176590   \n",
       "GEMMA 9B WITH SAE Masked                     4.076188               0.469673   \n",
       "\n",
       "                              P(Age|Error Ex)  Logit Diff (Error Ex)  \\\n",
       "method                                                                 \n",
       "VANILLA GEMMA 9B                     0.000997               6.925329   \n",
       "GEMMA 9B WITH SAE (no masks)         0.025586               2.025202   \n",
       "GEMMA 9B WITH SAE Masked             0.076615               1.813243   \n",
       "\n",
       "                              Cross-Entropy Loss  \n",
       "method                                            \n",
       "VANILLA GEMMA 9B                        0.027596  \n",
       "GEMMA 9B WITH SAE (no masks)            0.825018  \n",
       "GEMMA 9B WITH SAE Masked                0.424774  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "# Method: VANILLA GEMMA 9B\n",
    "method_name = \"VANILLA GEMMA 9B\"\n",
    "with torch.no_grad():\n",
    "    results = sanity_check_model_performance(baseline_logit_fn)\n",
    "    # Compute cross-entropy loss\n",
    "    ce_loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], baseline_logit_fn)\n",
    "    results['ce_loss'] = ce_loss\n",
    "    results['method'] = method_name\n",
    "    results_list.append(results)\n",
    "\n",
    "# Method: GEMMA 9B WITH SAE (no masks)\n",
    "method_name = \"GEMMA 9B WITH SAE (no masks)\"\n",
    "with torch.no_grad():\n",
    "    results = sanity_check_model_performance(baseline_sae_logit_fn)\n",
    "    # Compute cross-entropy loss\n",
    "    ce_loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], baseline_sae_logit_fn)\n",
    "    results['ce_loss'] = ce_loss\n",
    "    results['method'] = method_name\n",
    "    results_list.append(results)\n",
    "\n",
    "# Method: GEMMA 9B WITH SAE Masked\n",
    "method_name = \"GEMMA 9B WITH SAE Masked\"\n",
    "with torch.no_grad():\n",
    "    results = sanity_check_model_performance(masked_logit_fn)\n",
    "    # Compute cross-entropy loss\n",
    "    ce_loss = eval_ce_loss(simple_dataset[-1], simple_labels[-1], masked_logit_fn)\n",
    "    results['ce_loss'] = ce_loss\n",
    "    results['method'] = method_name\n",
    "    results_list.append(results)\n",
    "\n",
    "# Create a DataFrame and display it with descriptive column names\n",
    "df = pd.DataFrame(results_list)\n",
    "df = df.set_index('method')  # Set 'method' as the index\n",
    "\n",
    "# Rename columns for better readability\n",
    "df = df.rename(columns={\n",
    "    'prob_correct_in_correct': 'P(Age|Correct Ex)',\n",
    "    'prob_error_in_correct': 'P(Traceback|Correct Ex)',\n",
    "    'logit_diff_correct': 'Logit Diff (Correct Ex)',\n",
    "    'prob_error_in_error': 'P(Traceback|Error Ex)',\n",
    "    'prob_correct_in_error': 'P(Age|Error Ex)',\n",
    "    'logit_diff_error': 'Logit Diff (Error Ex)',\n",
    "    'ce_loss': 'Cross-Entropy Loss'\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group features by Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sparsemask(\"0.025_run.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(example).index(\"Emily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(example)[27]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,    480,    729, 235248, 235274, 235274]], device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_tokens(\"he was 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos>Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> age = {\\'Emily\\': 27, \\'James\\': 13, \\'Megan\\': 17, \\'Rob\\': 14, \\'Sam\\': 14}\\n>>> age[\"Emily\"]\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = simple_dataset[-2].clone()\n",
    "example[27] = 235284 # 2\n",
    "# example[28] = 235274 # 1\n",
    "model.to_string(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. iterate over last 10 examples\n",
    "data = simple_dataset[-10:]\n",
    "cached_activations = []\n",
    "with torch.no_grad():\n",
    "    def model_forward_pass(tokens):\n",
    "        return model.run_with_hooks(\n",
    "            tokens, \n",
    "            return_type=\"logits\", \n",
    "            fwd_hooks=build_hooks_list(tokens, use_mask=True, binarize_mask=True, cache_masked_activations=True)\n",
    "            )\n",
    "    for example in data:\n",
    "        logits = model_forward_pass(example)\n",
    "        cache = {}\n",
    "        for sae in saes:\n",
    "            cache[sae.cfg.hook_name] = sae.feature_acts\n",
    "        cached_activations.append(cache)\n",
    "\n",
    "    # print(model.to_string(example))\n",
    "    # logits = model_forward_pass(example)\n",
    "    # # logits = model_forward_pass(model.to_tokens(\"The sky is\"))\n",
    "    # print(model.to_str_tokens(torch.topk(F.softmax(logits[:, -1, :], dim=-1), k=3).indices))\n",
    "    # print(torch.topk(F.softmax(logits[:, -1, :], dim=-1), k=3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   75,  1575,  3231,  3524,  7008, 10180, 10647, 10768, 11635, 11740,\n",
      "        12571], device='cuda:0'),)\n",
      "<bos>Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> age = {'Sam': 11, 'Noah': 16, 'Megan': 19, 'Ava': 10, 'Lilly': 17}\n",
      ">>> age[\"Noah\"]\n",
      "\n",
      " age\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(torch.where(cached_activations[0][\"blocks.7.hook_resid_post\"][0][-5]))\n",
    "\n",
    "\n",
    "print(model.to_string(data[0]))\n",
    "print(model.to_str_tokens(data[0])[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 16384])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_activations[0][\"blocks.7.hook_resid_post\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   75,   351,   488,   632,  1229,  1422,  1575,  1589,  1662,  1935,\n",
      "         1976,  2467,  2701,  2846,  2881,  3153,  3231,  3257,  3354,  3418,\n",
      "         3524,  3658,  3784,  3992,  4287,  5196,  5311,  5337,  5459,  5537,\n",
      "         5587,  5778,  6491,  6500,  6535,  6671,  6800,  6928,  6984,  7008,\n",
      "         7024,  7323,  7857,  7958,  8146,  8667,  8895,  9046,  9052,  9353,\n",
      "         9513,  9681,  9843,  9850, 10093, 10094, 10180, 10267, 10647, 10680,\n",
      "        10768, 10868, 11204, 11526, 11635, 11707, 11740, 12131, 12134, 12275,\n",
      "        12387, 12407, 12571, 12880, 12956, 13383, 13630, 13635, 13694, 14249,\n",
      "        14309, 14342, 14567, 14615, 14827, 15328, 15462, 15613, 15678, 15738,\n",
      "        15796], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "keep_locations = torch.where(saes[0].mask.mask>0)[0]\n",
    "print(keep_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_seven_cache = torch.cat([cached_activations[i][\"blocks.7.hook_resid_post\"] for i in range(10)], dim=0)\n",
    "block_seven_cache = block_seven_cache[:, 1:, :].contiguous()\n",
    "block_seven_cache = block_seven_cache.view(-1, block_seven_cache.shape[-1])\n",
    "block_seven_cache = block_seven_cache[:, keep_locations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.6473,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [24.8756,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.8846],\n",
       "        [12.3906,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.3760],\n",
       "        ...,\n",
       "        [16.4783,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [22.2913,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [21.7554,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_seven_cache"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
